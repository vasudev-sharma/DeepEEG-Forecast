{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "vanilla_RNN_keras_GoogleColab_cross_correlation_stim_EEG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vs74/EEG/blob/LSTM/Notebooks/experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe31xP1M2ERH",
        "colab_type": "code",
        "outputId": "5c7e86bb-98f4-4d99-a804-c0520e5b086d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "rng = np.random\n",
        "from array import array\n",
        "from scipy import stats\n",
        "\n",
        "#Keras import \n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "from  tensorflow.keras import optimizers\n",
        "from  tensorflow.keras.callbacks import *\n",
        "\n",
        "#import models\n",
        "#from Linear_Regression import linear_regression \n",
        "\n",
        "#import datetime for tensorboard\n",
        "from datetime import *\n",
        "\n",
        "#Import for reading the MATLAB files\n",
        "import glob\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D51LpZw1b9Xr",
        "colab_type": "code",
        "outputId": "bdb12eee-fcda-4304-dfb3-7454bbf2d117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1filtered.mat  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7iXmRkG2K9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import for Loading EEG data from Google drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79_t3RkU2LHQ",
        "colab_type": "code",
        "outputId": "5b0bdf66-1dc9-460e-f233-0e27f839fc59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUkm-G4T1Ne4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Copy the content from the drive folder to the root directory\n",
        "!cp /content/drive/My\\ Drive/EEG_data/1filtered.mat /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6SHn7T55qdD",
        "colab_type": "code",
        "outputId": "9d5d9167-5bce-42e8-d6da-5e5fda4c2089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Check the data is downloaded or not\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1filtered.mat  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNdNq36P6mvb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8Vpq-qo5Yt6",
        "colab_type": "code",
        "outputId": "7650fecf-ba94-47db-8709-eb3174a660aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Ensure Google COlab is utilising GPU \n",
        "tf.test.gpu_device_name()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySSRppr02ERN",
        "colab_type": "code",
        "outputId": "d5b78dac-fa9e-4384-b767-0fc341c239fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Ensure that GPU memory utilisation is full\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=4ff694d579c31c16824bc122fccc92159571b36d88025749fa38a4252b08b4c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.1 GB  | Proc size: 576.0 MB\n",
            "GPU RAM Free: 16015MB | Used: 265MB | Util   2% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwtPhF572ERR",
        "colab_type": "code",
        "outputId": "9673a1c4-465d-48b0-c420-68a3b72414d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1filtered.mat  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "x5jjdQ5p2ERT",
        "colab_type": "code",
        "outputId": "5087385c-a7b3-4a26-c77d-77cbacfbe8e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "# data import from matlab\n",
        "subject_1 = sio.loadmat('1filtered.mat')      #recovering matlab data in the form of a python dictionar\n",
        "format_1 = subject_1['data']          #in the dictionary, only the data key interests us\n",
        "print (format_1.shape)\n",
        "\n",
        "# shuffle trials\n",
        "(channel, trial, time_points)= format_1.shape\n",
        "\n",
        "trials = np.arange(trial)\n",
        "np.random.shuffle(trials)\n",
        "\n",
        "#Z score\n",
        "format_1=stats.zscore(format_1, axis=2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(65, 192, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI4ZWx76sQpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualize Using Tenosrboard\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-RZqJH12ERc",
        "colab_type": "code",
        "outputId": "a293c104-fda5-4534-ce37-b30ad23a857a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# parametres\n",
        "\n",
        "eltmp = input ('''Enter the electrode number:''')\n",
        "electi = list(map(int, eltmp.split()))    #separation of the different responses and recovery in the form of a list of integers\n",
        "print (type(electi))\n",
        "print(electi)\n",
        "\n",
        "window = input ('''Enter the number of stimuli:''')\n",
        "window = int(window)\n",
        "\n",
        "n_channel = input('''Enter  the chanel number for which you want your predicion''')\n",
        "n_channel = list(map(int, n_channel.split()))\n",
        "\n",
        "\n",
        "relation = input('''Please define what should be predicted (1 for EEG from stimulus or 2 for stimulus from EEG or 3 for EEG forecasting ):''')\n",
        "\n",
        "if relation == '1':\n",
        "    response = input(\"Do you want to embed information of EEG as well ? ( 1 for yes or 2 for no)\")\n",
        "    if response == \"2\":\n",
        "      source_Y = electi[0]    #retrieving the electrode number as a whole number - implies that there is only one electrode chosen in this direction\n",
        "      source_X = [0]          #conversion of the stimuli line in the form of a list - necessary for the for loop: see below - extraction X\n",
        "    else:\n",
        "      source_Y = electi[0]\n",
        "      source_X = [0] + electi[0]\n",
        "\n",
        "elif relation == '2':\n",
        "    format_1 = np.flip(format_1,2)     # data inversion according to the time dimension - problem ????\n",
        "    source_Y = 0\n",
        "    source_X = electi\n",
        "    \n",
        "elif relation == '3':\n",
        "    response = input(\"Do you want to embed information of Stimuli as well ? ( 1 for yes or 2 for no)\") \n",
        "    if response == \"2\":\n",
        "      source_Y = n_channel\n",
        "      source_X = electi\n",
        "    else: \n",
        "      source_Y = n_channel\n",
        "      source_X = electi + [0]       \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the electrode number:1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 \n",
            "<class 'list'>\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
            "Enter the number of stimuli:160\n",
            "Enter  the chanel number for which you want your predicion1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 \n",
            "Please define what should be predicted (1 for EEG from stimulus or 2 for stimulus from EEG or 3 for EEG forecasting ):3\n",
            "Do you want to embed information of Stimuli as well ? ( 1 for yes or 2 for no)2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yodU9VVJ2ERe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### separation of train tests / valid / test\n",
        "\n",
        "train_num = int(np.around(len(trials) * 0.8))\n",
        "valid_num = int(np.around(len(trials) * 0.1))\n",
        "test_num = len(trials) - train_num - valid_num\n",
        "\n",
        "trials_train = trials[0:train_num]\n",
        "trials_valid = trials[train_num:train_num+valid_num]\n",
        "trials_test = trials[train_num+valid_num:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kUBgavduM0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trials_train = np.array([172, 125, 136,  99,  82,  31, 133,  44, 183, 184, 142, 121,  18,\n",
        "        89, 141,  27, 107,  49,  68, 186,  70,  92, 109,   6, 147, 124,\n",
        "       117, 161, 137,  39, 157, 159,   4,  23,  25, 145, 179, 118, 163,\n",
        "       106,  69, 187,  76, 108, 188,  32, 178,  19,  26,  72, 168, 158,\n",
        "        55,   8, 167,  11,  30,  59,  80,  95,  60, 148, 153,  45,  20,\n",
        "       152,  73,  48,  36, 100, 185, 131, 138,   3,  13,  97, 126, 171,\n",
        "       130,  54,   2,  50,  75,  83,  33, 174, 140,  79, 113, 146,  81,\n",
        "        64,  63,  46, 170,  16, 173, 156,  90, 103, 144,  29,  58,  47,\n",
        "       105, 189,  56,  34,  12, 165, 122, 119,  94,  42,  24,  37,  14,\n",
        "        65,  93,  87, 154,  77, 166, 114, 112, 160, 164,  51, 139,  84,\n",
        "       169,  85, 162,  88,  66, 155,  78,  28,   9,   1,  98, 132, 175,\n",
        "       177, 115,  96, 111,  52,  21, 180,  61, 191, 143,  10])\n",
        "\n",
        "trials_valid = np.array([ 67,  15,  38,  22,   0,  74, 182, 151,  91,  43,  53, 123, 127,\n",
        "       128, 149, 190, 134, 102, 181])\n",
        "\n",
        "trials_test = np.array([116,  57, 110,   7,  40, 176, 150,  41, 120, 135, 101,  71,  62,\n",
        "        86, 129,  35, 104,   5,  17])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhbP56DC4rX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rolling_window(a, window):\n",
        "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
        "    strides = a.strides + (a.strides[-1],)\n",
        "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbCiQ21d2ERf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract Y for Muti Channel Prediction\n",
        "def extract_Y (batch_trials, batch_num, horizon, multivariate = False):             #creation of a function to recover y - simplification of reading\n",
        "    y = []\n",
        "    for idx, i in enumerate(source_Y):\n",
        "      y_tmp = []\n",
        "      for j in batch_trials:\n",
        "        tmp = rolling_window(format_1[i, j, 160:], horizon)\n",
        "        y_tmp.append(tmp)\n",
        "      y.append(np.vstack(y_tmp))\n",
        "    if multivariate:\n",
        "      y= np.moveaxis(np.array(y), 0, -1)      \n",
        "    else: \n",
        "      y = np.hstack(y)  \n",
        "    return  y           \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSBFjfIo5IpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fcf5ff62-b44b-444d-d104-1de77cfdceb4"
      },
      "source": [
        "y_train = extract_Y (trials_train, train_num, horizon  = 1, multivariate= False)\n",
        "print (\"y_train.shape = \", y_train.shape)\n",
        "y_valid = extract_Y (trials_valid, valid_num, horizon  = 1, multivariate = False)\n",
        "print (\"y_valid.shape = \", y_valid.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train.shape =  (129360, 64)\n",
            "y_valid.shape =  (15960, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uXbroV5eQNz",
        "colab_type": "code",
        "outputId": "5025b150-f6df-4379-aa75-81ef7a730839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test = extract_Y (trials_test, test_num, horizon  = 840, multivariate = True)\n",
        "print (\"y_test.shape = \", y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_test.shape =  (19, 840, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J679vPOeiYQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def extract_X (batch_trials, batch_num, horizon = 1):                     #creation of a function to recover x - simplification of reading\n",
        "  \n",
        "    x = np.zeros((len(source_X),  batch_num * (time_points - window - horizon + 1 ), window ))                                     \n",
        "    for idx, i in enumerate(source_X):                                      #reading the source list -> reading each electrode number if flip\n",
        "      x_tmp = []\n",
        "      for j in batch_trials:\n",
        "        tmp = rolling_window(format_1[i, j, :-horizon], window)\n",
        "        x_tmp.append(tmp)\n",
        "      x[idx] = np.vstack(x_tmp)\n",
        "\n",
        "    x = np.hstack(x)\n",
        "    x = np.array(np.split(x, len(source_X), axis = -1))\n",
        "    x = np.moveaxis(x, 0, -1)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StMDf0gOe9WX",
        "colab_type": "code",
        "outputId": "c8e35474-63ee-40ca-9a56-ffb2cd387e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "x_train = extract_X (trials_train, train_num, horizon = 1)\n",
        "print (\"x_train.shape = \", x_train.shape)\n",
        "x_valid = extract_X (trials_valid, valid_num, horizon = 1)\n",
        "print (\"x_valid.shape = \", x_valid.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape =  (129360, 160, 64)\n",
            "x_valid.shape =  (15960, 160, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rFC7L7re0lk",
        "colab_type": "code",
        "outputId": "e5a4021f-24f2-4885-d415-a3e38056728f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "x_test = extract_X (trials_test, test_num, horizon = 840)\n",
        "print (\"x_test.shape = \", x_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test.shape =  (19, 160, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YADYrkgq2ERk",
        "colab_type": "code",
        "outputId": "dd863c92-92a6-4c01-8241-5f8e779dccfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "train_X = x_train\n",
        "print(train_X.shape)\n",
        "train_Y = y_train\n",
        "print(train_Y.shape)\n",
        "n_samples_train = train_X.shape[0]\n",
        "\n",
        "valid_X = x_valid\n",
        "valid_Y = y_valid\n",
        "n_samples_valid = valid_X.shape[0]\n",
        "\n",
        "test_X = x_test\n",
        "test_Y = y_test\n",
        "n_samples_test = test_X.shape[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(129360, 160, 64)\n",
            "(129360, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FefOyH9eLMi3",
        "colab_type": "code",
        "outputId": "c96d9a0c-14b3-4cc5-e0f7-d77577a83dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Sanity Check dimension of Inout\n",
        "print(\"Shape of Train_X  = \", train_X.shape)\n",
        "print(\"Shape of Valid_X  = \", valid_X.shape)\n",
        "print(\"Shape of Test_X   = \",test_X.shape )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Train_X  =  (129360, 160, 64)\n",
            "Shape of Valid_X  =  (15960, 160, 64)\n",
            "Shape of Test_X   =  (19, 160, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3-uB5j6WWwn",
        "colab_type": "code",
        "outputId": "4ac03fbc-696c-4f1c-be86-1cc2ff3e1379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ab4e10c4b9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpQCMPFmWkPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import LSTMCell, GRUCell, RNN, SimpleRNNCell, Dense, Input, Flatten, Concatenate\n",
        "from keras import Model\n",
        "from keras import backend as K\n",
        "from keras.metrics import get\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHXZ_vPIoVpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"LSTM\"\n",
        "optimizer_name = \"sgd\"\n",
        "training_epochs = 200\n",
        "batch_size = 1024\n",
        "\n",
        "layers = 1\n",
        "learning_rate = 0.1\n",
        "normalized_data = True\n",
        "features = train_X.shape[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1MHdvPEcSsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class RecurrentNN(object):\n",
        "    \"\"\"\n",
        "    A wrapper around the RNN, LSTM and GRU classes that allows to build model\n",
        "    and performs predictions using two different multi-step forecasting strategies:\n",
        "    Multiple Input Multiple Output (MIMO) and Recursive\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layers, cell_type, cell_params):\n",
        "        \"\"\"\n",
        "        Build the rnn with the given number of layers.\n",
        "        :param layers: list\n",
        "            list of integers. The i-th element of the list is the number of hidden neurons for the i-th layer.\n",
        "        :param cell_type: 'gru', 'rnn', 'lstm'\n",
        "        :param cell_params: dict\n",
        "            A dictionary containing all the paramters for the RNN cell.\n",
        "            see keras.layers.LSTMCell, keras.layers.GRUCell or keras.layers.SimpleRNNCell for more details.\n",
        "        \"\"\"\n",
        "        # init params\n",
        "        self.model = None\n",
        "        self.horizon = None\n",
        "        self.layers = layers\n",
        "        self.cell_params = cell_params\n",
        "        if cell_type == 'lstm':\n",
        "            self.cell = LSTMCell\n",
        "        elif cell_type == 'gru':\n",
        "            self.cell = GRUCell\n",
        "        elif cell_type == 'rnn':\n",
        "            self.cell = SimpleRNNCell\n",
        "        else:\n",
        "            raise NotImplementedError('{0} is not a valid cell type.'.format(cell_type))\n",
        "        # Build deep rnn\n",
        "        self.rnn = self._build_rnn()\n",
        "\n",
        "    def _build_rnn(self):\n",
        "        cells = []\n",
        "        for _ in range(self.layers):\n",
        "            cells.append(self.cell(**self.cell_params))\n",
        "        deep_rnn = RNN(cells, return_sequences=False, return_state=False)\n",
        "        return deep_rnn\n",
        "\n",
        "    def build_model(self, input_shape, horizon):\n",
        "        pass\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        pass\n",
        "\n",
        "    def evaluate(self, inputs):\n",
        "        pass\n",
        "\n",
        "    def _eval(self, y, y_hat):\n",
        "        results = []\n",
        "        for m in self.model.metrics:\n",
        "            if isinstance(m, str):\n",
        "                results.append(K.eval(K.mean(get(m)(y, y_hat))))\n",
        "            else:\n",
        "                results.append(K.eval(K.mean(m(y, y_hat))))\n",
        "        return results\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qYv0mNIWeuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class RecurrentNN_Rec(RecurrentNN):\n",
        "    \"\"\"\n",
        "    Recurrent Neural network using Recursive forecasting startegy.\n",
        "    The model's training and predictions phase are different.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.return_sequence = False\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def build_model(self, input_shape, horizon):\n",
        "        \"\"\"\n",
        "        Create a Model that takes as inputs:\n",
        "            - 3D Tensor of shape (batch_size, window_size, n_features)\n",
        "        and outputs:\n",
        "            - 2D tensor of shape (batch_size, 1)\n",
        "        :param input_shape:\n",
        "            (window_size, n_features)\n",
        "        :param horizon: int\n",
        "            The forecasting horizon\n",
        "        :return: a keras Model\n",
        "        \"\"\"\n",
        "        self.horizon = horizon\n",
        "        if len(input_shape) < 2:\n",
        "            input_shape = (input_shape[0], 1)\n",
        "        inputs = Input(shape=input_shape, dtype='float32')\n",
        "        out_rnn = self.rnn(inputs)                    # [batch_size, hidden_state_length]\n",
        "        outputs = Dense(1, activation=None)(out_rnn)  # [batch_size, 1]\n",
        "\n",
        "        self.model = Model(inputs=[inputs], outputs=[outputs])\n",
        "        self.model.summary()\n",
        "        print(\"Hello\")\n",
        "        return self.model\n",
        "\n",
        "    def predict(self, inputs, exogenous=None):\n",
        "        \"\"\"\n",
        "        Perform recursive prediction by feeding the network input at time t+1 with the prediction at\n",
        "        time t. This is repeted 'horizon' number of time.\n",
        "        :param input: np.array\n",
        "            (batch_size, window_size, n_features), n_features is supposed to be 1 (univariate time-series)\n",
        "        :param exogenous: np.array\n",
        "            exogenous feature for the loads to be predicted\n",
        "            (batch_size, horizon, n_exog_features)\n",
        "        :return: np.array\n",
        "            (batch_size, horizon)\n",
        "        \"\"\"\n",
        "        input_seq = inputs                                         # (batch_size, n_timestamps, n_features)\n",
        "        output_seq = np.zeros((input_seq.shape[0], self.horizon))  # (batch_size, horizon)\n",
        "        for i in tqdm(range(self.horizon)):\n",
        "            if self.return_sequence:\n",
        "                output = self.model.predict(input_seq)             # [batch_size, input_timesteps]\n",
        "                output = output[:,-1:]\n",
        "            else:\n",
        "                output = self.model.predict(input_seq)             # [batch_size, 1]\n",
        "            input_seq[:, :-1, :] = input_seq[:, 1:, :]\n",
        "            input_seq[:, -1:, 0] = output\n",
        "            if exogenous is not None:\n",
        "                input_seq[:, -1, 1:] = exogenous[:, i, :]\n",
        "            # input_seq = np.concatenate([input_seq[:, 1:, :], np.expand_dims(output,axis=-1)], axis=1)\n",
        "            output_seq[:, i] = output[:,0]\n",
        "        return output_seq\n",
        "\n",
        "    def evaluate(self, inputs, fn_inverse=None, fn_plot=None):\n",
        "        try:\n",
        "            X, y = inputs\n",
        "        except:\n",
        "            X, y, _ = inputs\n",
        "        try:\n",
        "            X, exogenous = X\n",
        "        except:\n",
        "            exogenous = None\n",
        "        print(y.shape)\n",
        "        y_hat = self.predict(X, exogenous)\n",
        "\n",
        "        return y_hat\n",
        "\n",
        "        '''\n",
        "        if fn_inverse is not None:\n",
        "            y_hat = fn_inverse(y_hat)\n",
        "            y = fn_inverse(y)\n",
        "\n",
        "        if fn_plot is not None:\n",
        "            fn_plot([y, y_hat])\n",
        "\n",
        "        return self._eval(y, y_hat)\n",
        "        '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMgZdbDMcaNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class RecurrentNN_MIMO(RecurrentNN):\n",
        "    \"\"\"\n",
        "    Recurrent Neural network using MIMO forecasting startegy.\n",
        "    \"\"\"\n",
        "\n",
        "    def build_model(self, input_shape, horizon, exogenous_shape=None):\n",
        "        \"\"\"\n",
        "        Create a Model that takes as inputs:\n",
        "            - 3D Tensor of shape (batch_size, window_size, n_features)\n",
        "            - (optional) 3D Tensor of shape (batch_size, window_size, n_features-1)\n",
        "        and outputs:\n",
        "            - 2D tensor of shape (batch_size, horizon)\n",
        "        :param input_shape:\n",
        "            (window_size, n_features)\n",
        "        :param horizon: int\n",
        "            The forecasting horizon\n",
        "        :param conditions_shape:\n",
        "            (horizon, n_features)\n",
        "        :return: a keras Model\n",
        "        \"\"\"\n",
        "        self.horizon = horizon\n",
        "        if len(input_shape) < 2:\n",
        "            input_shape = (input_shape[0], 1)\n",
        "        inputs = Input(shape=input_shape, dtype='float32', name='input')\n",
        "        # [batch_size, hidden_state_length]\n",
        "        out_rnn = self.rnn(inputs)\n",
        "\n",
        "        if exogenous_shape is not None:\n",
        "            # Include exogenous in the prediction\n",
        "            exogenous = Input(exogenous_shape, dtype='float32', name='exogenous')  # [batch_size, horizon, n_features]\n",
        "            out_rnn = Dense(horizon, activation='relu')(out_rnn)\n",
        "            ex = Flatten()(exogenous)                                              # [batch_size, horizon * n_features]\n",
        "            ex = Dense(horizon, activation='relu')(ex)\n",
        "            out_rnn = Concatenate()([out_rnn, ex])                                 # [batch_size, 2*horizon]\n",
        "\n",
        "        # [batch_size, horizon]\n",
        "        outputs = Dense(horizon, activation=None)(out_rnn)\n",
        "\n",
        "        if exogenous_shape is not None:\n",
        "            self.model = Model(inputs=[inputs, exogenous], outputs=outputs)\n",
        "        else:\n",
        "            self.model = Model(inputs=[inputs], outputs=[outputs])\n",
        "        self.model.summary()\n",
        "        return self.model\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"\n",
        "        :param inputs: np.array\n",
        "            (batch_size, window_size, n_features)\n",
        "        :return: np.array\n",
        "            (batch_size, horizon)\n",
        "        \"\"\"\n",
        "        return self.model.predict(inputs)\n",
        "\n",
        "    def evaluate(self, inputs, fn_inverse=None, fn_plot=None):\n",
        "        try:\n",
        "            X, y_exog, y = inputs\n",
        "            y_hat = self.model.predict([X, y_exog])\n",
        "        except:\n",
        "            X, y = inputs\n",
        "            y_hat = self.model.predict(X)\n",
        "        y_hat = np.asarray(y_hat, dtype=y.dtype)\n",
        "\n",
        "\n",
        "        return y_hat\n",
        "        '''\n",
        "\n",
        "        if fn_inverse is not None:\n",
        "            y_hat = fn_inverse(y_hat)\n",
        "            y = fn_inverse(y)\n",
        "\n",
        "        if fn_plot is not None:\n",
        "            fn_plot([y, y_hat])\n",
        "\n",
        "        return self._eval(y, y_hat)\n",
        "        '''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO4zitx7n_0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBGyxEHonpEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  cell_params = dict(units=units,\n",
        "                      activation='tanh',\n",
        "                      dropout=0.1,\n",
        "                      kernel_regularizer=l2(0.001),\n",
        "                      recurrent_regularizer=l2(0.001),\n",
        "                      kernel_initializer='lecun_uniform',\n",
        "                      recurrent_initializer='lecun_uniform')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXzXh98WoB-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = RecurrentNN_Rec(cell_type='lstm',\n",
        "                              layers=1,\n",
        "                              cell_params=cell_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKAQiSULo-YV",
        "colab_type": "code",
        "outputId": "a15b9bc1-38b3-47c1-af2a-cf4918abcd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model = rnn.build_model(input_shape=(160, 1),\n",
        "                                horizon=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 160, 1)            0         \n",
            "_________________________________________________________________\n",
            "rnn_9 (RNN)                  (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAMxT_o0pb6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set up the Optimizers\n",
        "sgd = optimizers.SGD(learning_rate)\n",
        "adam = optimizers.Adam(lr = learning_rate)\n",
        "rmsprop = optimizers.RMSprop(lr = learning_rate)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss = \"mse\", optimizer = sgd , metrics=[\"mse\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvV4yfdZpLu8",
        "colab_type": "code",
        "outputId": "13c6371c-9059-489b-ba47-6243d3debe50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        " history = model.fit(x_train, y_train,\n",
        "                        validation_data = (x_valid, y_valid),\n",
        "                        batch_size = 1024,\n",
        "                        # steps_per_epoch= train.shape[0] // params['batch_size'],\n",
        "                        epochs=200,\n",
        "                        verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 129360 samples, validate on 15960 samples\n",
            "Epoch 1/20\n",
            "129360/129360 [==============================] - 40s 309us/step - loss: 0.8210 - mean_squared_error: 0.7757 - val_loss: 0.7629 - val_mean_squared_error: 0.7176\n",
            "Epoch 2/20\n",
            "129360/129360 [==============================] - 39s 300us/step - loss: 0.7838 - mean_squared_error: 0.7385 - val_loss: 0.7266 - val_mean_squared_error: 0.6813\n",
            "Epoch 3/20\n",
            "129360/129360 [==============================] - 38s 297us/step - loss: 0.7525 - mean_squared_error: 0.7073 - val_loss: 0.6962 - val_mean_squared_error: 0.6509\n",
            "Epoch 4/20\n",
            "129360/129360 [==============================] - 38s 296us/step - loss: 0.7262 - mean_squared_error: 0.6810 - val_loss: 0.6704 - val_mean_squared_error: 0.6252\n",
            "Epoch 5/20\n",
            "129360/129360 [==============================] - 39s 298us/step - loss: 0.7041 - mean_squared_error: 0.6589 - val_loss: 0.6482 - val_mean_squared_error: 0.6031\n",
            "Epoch 6/20\n",
            "129360/129360 [==============================] - 39s 298us/step - loss: 0.6848 - mean_squared_error: 0.6396 - val_loss: 0.6289 - val_mean_squared_error: 0.5838\n",
            "Epoch 7/20\n",
            "129360/129360 [==============================] - 39s 300us/step - loss: 0.6676 - mean_squared_error: 0.6225 - val_loss: 0.6119 - val_mean_squared_error: 0.5668\n",
            "Epoch 8/20\n",
            "129360/129360 [==============================] - 38s 297us/step - loss: 0.6514 - mean_squared_error: 0.6063 - val_loss: 0.5967 - val_mean_squared_error: 0.5516\n",
            "Epoch 9/20\n",
            "129360/129360 [==============================] - 39s 298us/step - loss: 0.6382 - mean_squared_error: 0.5931 - val_loss: 0.5829 - val_mean_squared_error: 0.5378\n",
            "Epoch 10/20\n",
            "129360/129360 [==============================] - 39s 301us/step - loss: 0.6261 - mean_squared_error: 0.5810 - val_loss: 0.5703 - val_mean_squared_error: 0.5252\n",
            "Epoch 11/20\n",
            "129360/129360 [==============================] - 39s 302us/step - loss: 0.6135 - mean_squared_error: 0.5684 - val_loss: 0.5587 - val_mean_squared_error: 0.5136\n",
            "Epoch 12/20\n",
            "129360/129360 [==============================] - 39s 302us/step - loss: 0.6030 - mean_squared_error: 0.5580 - val_loss: 0.5479 - val_mean_squared_error: 0.5029\n",
            "Epoch 13/20\n",
            "129360/129360 [==============================] - 39s 304us/step - loss: 0.5928 - mean_squared_error: 0.5478 - val_loss: 0.5379 - val_mean_squared_error: 0.4929\n",
            "Epoch 14/20\n",
            "129360/129360 [==============================] - 39s 304us/step - loss: 0.5832 - mean_squared_error: 0.5382 - val_loss: 0.5285 - val_mean_squared_error: 0.4836\n",
            "Epoch 15/20\n",
            "129360/129360 [==============================] - 39s 304us/step - loss: 0.5751 - mean_squared_error: 0.5302 - val_loss: 0.5196 - val_mean_squared_error: 0.4746\n",
            "Epoch 16/20\n",
            "129360/129360 [==============================] - 39s 303us/step - loss: 0.5670 - mean_squared_error: 0.5220 - val_loss: 0.5112 - val_mean_squared_error: 0.4663\n",
            "Epoch 17/20\n",
            "129360/129360 [==============================] - 39s 302us/step - loss: 0.5573 - mean_squared_error: 0.5124 - val_loss: 0.5032 - val_mean_squared_error: 0.4583\n",
            "Epoch 18/20\n",
            "129360/129360 [==============================] - 39s 303us/step - loss: 0.5513 - mean_squared_error: 0.5064 - val_loss: 0.4956 - val_mean_squared_error: 0.4507\n",
            "Epoch 19/20\n",
            "129360/129360 [==============================] - 39s 301us/step - loss: 0.5426 - mean_squared_error: 0.4978 - val_loss: 0.4883 - val_mean_squared_error: 0.4435\n",
            "Epoch 20/20\n",
            "129360/129360 [==============================] - 39s 303us/step - loss: 0.5361 - mean_squared_error: 0.4913 - val_loss: 0.4814 - val_mean_squared_error: 0.4366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSQtoWaMiOD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, input, horizon = 2, return_sequence = False):\n",
        "    \"\"\"\n",
        "    Perform recursive prediction by feeding the network input at time t+1 with the prediction at\n",
        "    time t. This is repeted 'horizon' number of time.\n",
        "    :param input: np.array\n",
        "        (batch_size, window_size, n_features), n_features is supposed to be 1 (univariate time-series)\n",
        "    :param exogenous: np.array\n",
        "        exogenous feature for the loads to be predicted\n",
        "        (batch_size, horizon, n_exog_features)\n",
        "    :return: np.array\n",
        "        (batch_size, horizon)\n",
        "    \"\"\"\n",
        "    input_seq = input                                         # (batch_size, n_timestamps, n_features)\n",
        "    output_seq = np.zeros((input_seq.shape[0], horizon, input_seq.shape[-1] - 1))  # (batch_size, horizon, n_features)\n",
        "    for i in tqdm(range(horizon)):\n",
        "        if return_sequence:\n",
        "            output = model.predict(input_seq, verbose = 1)             # [batch_size, input_timesteps]\n",
        "            output = output[:,-1:]\n",
        "        else:\n",
        "            output = model.predict(input_seq, verbose = 1)             # [batch_size, n_features]\n",
        "            print(output.shape)\n",
        "        input_seq[:, :-1, :] = input_seq[:, 1:, :]                    \n",
        "        print(input_seq.shape)\n",
        "        print(output_seq.shape)\n",
        "        input_seq[:, -1:, 1:] = output\n",
        "        '''if exogenous is not None:\n",
        "            input_seq[:, -1, 1:] = exogenous[:, i, :]\n",
        "        '''\n",
        "        # input_seq = np.concatenate([input_seq[:, 1:, :], np.expand_dims(output,axis=-1)], axis=1)\n",
        "        output_seq[:, i, :] = output[:,0]\n",
        "    return output_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvl2EoKdiymW",
        "colab_type": "code",
        "outputId": "9c5687f0-3cb3-4a4a-e37f-afc60cd77e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "predictions = predict(model, x_test, horizon = 840)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/840 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r19/19 [==============================] - 0s 3ms/sample\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/840 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(19, 64)\n",
            "(19, 160, 65)\n",
            "(19, 840, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-d8476cb7302b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m840\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-40f121a9b1c2>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, input, horizon, return_sequence)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         '''if exogenous is not None:\n\u001b[1;32m     27\u001b[0m             \u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexogenous\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (19,64) into shape (19,1,65)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHlv70P1a5td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OGu9xusj_TF",
        "colab_type": "code",
        "outputId": "06fd6771-38b1-452c-bf21-9a9d09ee4edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15941, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEw1hoYXlT3A",
        "colab_type": "code",
        "outputId": "988fd3ba-bd0e-49ed-c4ae-883e3ce1dc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.3953069 ,  2.7110921 ],\n",
              "       [ 2.7110921 ,  2.95549735],\n",
              "       [ 2.95549735,  2.43877453],\n",
              "       ...,\n",
              "       [-0.92890832, -0.56058633],\n",
              "       [-0.56058633, -0.74179912],\n",
              "       [-0.74179912, -0.39280196]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLNVA3Dqkn9s",
        "colab_type": "code",
        "outputId": "d54e7607-58c4-45c9-8068-0687d37a8c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.55388373,  0.60830188],\n",
              "       [ 0.56456625,  0.59624112],\n",
              "       [ 0.54436743,  0.57120228],\n",
              "       ...,\n",
              "       [-0.95175695, -0.88760197],\n",
              "       [-0.88382959, -0.87295794],\n",
              "       [-0.81254745, -0.83628845]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-HASBFpkuM7",
        "colab_type": "code",
        "outputId": "868cc0dc-cfc3-4e1d-e212-42b1c9139529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "r"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.61603963,  0.61068666],\n",
              "       [ 0.59882915,  0.59112507],\n",
              "       [ 0.57742494,  0.57052612],\n",
              "       ...,\n",
              "       [-0.87472141, -0.87066698],\n",
              "       [-0.86917818, -0.86540365],\n",
              "       [-0.83611655, -0.83188939]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mIbrKVBkCf-",
        "colab_type": "code",
        "outputId": "b7d91b69-9314-40d1-f3c9-45ec1024b959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15941, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tYYMtKetosH",
        "colab_type": "code",
        "outputId": "f018b414-be87-4797-f492-0f39afd50dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "r = rnn.evaluate([x_test, y_test])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(15941, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:50<00:50, 50.66s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:41<00:00, 50.55s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNCKke5tuEmf",
        "colab_type": "code",
        "outputId": "f29c049b-6f1a-432d-a9fa-e6e233cdfc09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_scores.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15960, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2H9iPHJrhyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "24be38c3-ee7a-41b6-ef2f-30dcf431a8bb"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrwgHZ1blLew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parameters of model\n",
        "model_name = \"LSTM\"\n",
        "optimizer_name = \"sgd\"\n",
        "training_epochs = 200\n",
        "batch_size = 1024\n",
        "layers = 1\n",
        "units = 95\n",
        "learning_rate = 0.1\n",
        "activation = \"relu\"\n",
        "features = train_X.shape[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFln5PJ5jL-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def predict(self, inputs, exogenous=None):\n",
        "        \"\"\"\n",
        "        Perform recursive prediction by feeding the network input at time t+1 with the prediction at\n",
        "        time t. This is repeted 'horizon' number of time.\n",
        "        :param input: np.array\n",
        "            (batch_size, window_size, n_features), n_features is supposed to be 1 (univariate time-series)\n",
        "        :param exogenous: np.array\n",
        "            exogenous feature for the loads to be predicted\n",
        "            (batch_size, horizon, n_exog_features)\n",
        "        :return: np.array\n",
        "            (batch_size, horizon)\n",
        "        \"\"\"\n",
        "        input_seq = inputs                                         # (batch_size, n_timestamps, n_features)\n",
        "        output_seq = np.zeros((input_seq.shape[0], self.horizon))  # (batch_size, horizon)\n",
        "        for i in tqdm(range(self.horizon)):\n",
        "            if self.return_sequence:\n",
        "                output = self.model.predict(input_seq)             # [batch_size, input_timesteps]\n",
        "                output = output[:,-1:]\n",
        "            else:\n",
        "                output = self.model.predict(input_seq)             # [batch_size, 1]\n",
        "            input_seq[:, :-1, :] = input_seq[:, 1:, :]\n",
        "            input_seq[:, -1:, 0] = output\n",
        "            if exogenous is not None:\n",
        "                input_seq[:, -1, 1:] = exogenous[:, i, :]\n",
        "            # input_seq = np.concatenate([input_seq[:, 1:, :], np.expand_dims(output,axis=-1)], axis=1)\n",
        "            output_seq[:, i] = output[:,0]\n",
        "        return output_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2MSn7F52ERo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vanilla_RNN(layers, units, features):\n",
        "    inp = Input([window, features])\n",
        "    X = inp\n",
        "    for i in range(layers - 1):\n",
        "      X = LSTM(units, return_sequences = True)(X)\n",
        "    X = LSTM(units)(X)\n",
        "    out = Dense(len(source_Y), kernel_initializer = 'normal')(X)\n",
        "    \n",
        "    model = Model(inputs = inp, outputs = out)\n",
        "    #Set up the Optimizers\n",
        "    sgd = optimizers.SGD(learning_rate)\n",
        "    adam = optimizers.Adam(lr = learning_rate)\n",
        "    rmsprop = optimizers.RMSprop(lr = learning_rate)\n",
        "\n",
        "    #Compile the model\n",
        "    model.compile(loss = \"mse\", optimizer = sgd , metrics=[\"mse\"])\n",
        "    return model \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUwdv98D2ERq",
        "colab_type": "code",
        "outputId": "054dfd8d-92d7-45ef-ddc1-e992b9556a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#Define Keras Model \n",
        "model = vanilla_RNN( layers, units, features)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzzmVgF52ERs",
        "colab_type": "code",
        "outputId": "5ed48a30-b10f-4330-fe4d-caeed23008ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "hidden_layers"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8187eea99788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhidden_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'hidden_layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sItsf9bB3ekW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAqrciJC2ERu",
        "colab_type": "code",
        "outputId": "961e831c-fe9c-4694-c40c-e516079e36c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 160, 65)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 95)                61180     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                6144      \n",
            "=================================================================\n",
            "Total params: 67,324\n",
            "Trainable params: 67,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVZzuKSg6RPV",
        "colab_type": "code",
        "outputId": "5cee826a-1890-40ee-eb57-56f9934c7902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Make Directory to store Tenorboad Logs\n",
        "!mkdir logs\n",
        "!mkdir logs/scalars"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜logsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜logs/scalarsâ€™: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk8S5zgjnTC7",
        "colab_type": "code",
        "outputId": "2f5ac642-e89f-4214-b37e-47fa79040c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!apt-get install tree\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tree is already the newest version (1.7.0-5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwEV8jz5phDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainValTensorBoard(TensorBoard):\n",
        "    def __init__(self, log_dir='./logs', **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "        training_log_dir = os.path.join(log_dir, 'training')\n",
        "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
        "\n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
        "        super(TrainValTensorBoard, self).set_model(model)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "        for name, value in val_logs.items():\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.val_writer.add_summary(summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "\n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
        "        self.val_writer.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6awBoWU2ERw",
        "colab_type": "code",
        "outputId": "79501d89-d7ad-4ec0-bb86-05a910d23f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Set Up Tensorboard for visualisation for training\n",
        "Name = \"{} + optimizer_{} + batch_size_{} + epochs_{} + Layer_{} + units_{} + learning_rate_{} +  activation_{} + relation_{} + date_\".format(model_name, optimizer_name, batch_size, training_epochs, layers, units, learning_rate, activation, relation)\n",
        "logdir =\"logs/scalars/\"+ Name + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TrainValTensorBoard(log_dir=logdir, write_images = True, histogram_freq = 2)\n",
        "#Sanity Check for LogDir\n",
        "print(logdir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logs/scalars/LSTM + optimizer_sgd + batch_size_1024 + epochs_10 + Layer_1 + units_95 + learning_rate_0.1 +  activation_relu + relation_3 + date_20200323-183111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Shr84Zt2feB",
        "colab_type": "code",
        "outputId": "e81dc887-83c9-4c9d-b1b0-6f7cf8d0f24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "LOG_DIR = 'logs/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "#Get url of TensorBoard to Visualise\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n",
            "    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEB9DElnrCbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_epochs = 200\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ15oWpYrwCW",
        "colab_type": "code",
        "outputId": "6d55e98b-ecbe-4ec8-b65f-268f9c4715d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Fit the model with the Data\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, \n",
        "    y_train, \n",
        "    validation_data= (x_valid, y_valid),\n",
        "    batch_size = batch_size,\n",
        "    epochs = training_epochs,\n",
        "    verbose = 1,\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 129360 samples, validate on 15960 samples\n",
            "Epoch 1/200\n",
            "129360/129360 [==============================] - 36s 280us/sample - loss: 0.8674 - mean_squared_error: 0.8674 - val_loss: 0.7888 - val_mean_squared_error: 0.7888\n",
            "Epoch 2/200\n",
            "129360/129360 [==============================] - 36s 275us/sample - loss: 0.7520 - mean_squared_error: 0.7520 - val_loss: 0.7176 - val_mean_squared_error: 0.7176\n",
            "Epoch 3/200\n",
            "129360/129360 [==============================] - 35s 273us/sample - loss: 0.6998 - mean_squared_error: 0.6998 - val_loss: 0.6778 - val_mean_squared_error: 0.6778\n",
            "Epoch 4/200\n",
            "129360/129360 [==============================] - 35s 271us/sample - loss: 0.6647 - mean_squared_error: 0.6647 - val_loss: 0.6470 - val_mean_squared_error: 0.6470\n",
            "Epoch 5/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.6353 - mean_squared_error: 0.6353 - val_loss: 0.6202 - val_mean_squared_error: 0.6202\n",
            "Epoch 6/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.6092 - mean_squared_error: 0.6092 - val_loss: 0.5962 - val_mean_squared_error: 0.5962\n",
            "Epoch 7/200\n",
            "129360/129360 [==============================] - 35s 271us/sample - loss: 0.5857 - mean_squared_error: 0.5857 - val_loss: 0.5747 - val_mean_squared_error: 0.5747\n",
            "Epoch 8/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.5643 - mean_squared_error: 0.5643 - val_loss: 0.5550 - val_mean_squared_error: 0.5550\n",
            "Epoch 9/200\n",
            "129360/129360 [==============================] - 35s 273us/sample - loss: 0.5449 - mean_squared_error: 0.5449 - val_loss: 0.5372 - val_mean_squared_error: 0.5372\n",
            "Epoch 10/200\n",
            "129360/129360 [==============================] - 35s 273us/sample - loss: 0.5273 - mean_squared_error: 0.5273 - val_loss: 0.5209 - val_mean_squared_error: 0.5209\n",
            "Epoch 11/200\n",
            "129360/129360 [==============================] - 35s 273us/sample - loss: 0.5112 - mean_squared_error: 0.5112 - val_loss: 0.5062 - val_mean_squared_error: 0.5062\n",
            "Epoch 12/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.4967 - mean_squared_error: 0.4967 - val_loss: 0.4928 - val_mean_squared_error: 0.4928\n",
            "Epoch 13/200\n",
            "129360/129360 [==============================] - 35s 271us/sample - loss: 0.4837 - mean_squared_error: 0.4837 - val_loss: 0.4809 - val_mean_squared_error: 0.4809\n",
            "Epoch 14/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.4720 - mean_squared_error: 0.4720 - val_loss: 0.4702 - val_mean_squared_error: 0.4702\n",
            "Epoch 15/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.4616 - mean_squared_error: 0.4616 - val_loss: 0.4607 - val_mean_squared_error: 0.4607\n",
            "Epoch 16/200\n",
            "129360/129360 [==============================] - 35s 271us/sample - loss: 0.4522 - mean_squared_error: 0.4522 - val_loss: 0.4521 - val_mean_squared_error: 0.4521\n",
            "Epoch 17/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.4438 - mean_squared_error: 0.4438 - val_loss: 0.4443 - val_mean_squared_error: 0.4443\n",
            "Epoch 18/200\n",
            "129360/129360 [==============================] - 35s 271us/sample - loss: 0.4361 - mean_squared_error: 0.4361 - val_loss: 0.4372 - val_mean_squared_error: 0.4372\n",
            "Epoch 19/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.4291 - mean_squared_error: 0.4291 - val_loss: 0.4307 - val_mean_squared_error: 0.4307\n",
            "Epoch 20/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.4226 - mean_squared_error: 0.4226 - val_loss: 0.4248 - val_mean_squared_error: 0.4248\n",
            "Epoch 21/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.4167 - mean_squared_error: 0.4167 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
            "Epoch 22/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.4111 - mean_squared_error: 0.4111 - val_loss: 0.4140 - val_mean_squared_error: 0.4140\n",
            "Epoch 23/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.4060 - mean_squared_error: 0.4060 - val_loss: 0.4092 - val_mean_squared_error: 0.4092\n",
            "Epoch 24/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.4012 - mean_squared_error: 0.4012 - val_loss: 0.4047 - val_mean_squared_error: 0.4047\n",
            "Epoch 25/200\n",
            "129360/129360 [==============================] - 35s 271us/sample - loss: 0.3967 - mean_squared_error: 0.3967 - val_loss: 0.4005 - val_mean_squared_error: 0.4005\n",
            "Epoch 26/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.3926 - mean_squared_error: 0.3926 - val_loss: 0.3966 - val_mean_squared_error: 0.3966\n",
            "Epoch 27/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3887 - mean_squared_error: 0.3887 - val_loss: 0.3929 - val_mean_squared_error: 0.3929\n",
            "Epoch 28/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3850 - mean_squared_error: 0.3850 - val_loss: 0.3895 - val_mean_squared_error: 0.3895\n",
            "Epoch 29/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.3861 - val_mean_squared_error: 0.3861\n",
            "Epoch 30/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3784 - mean_squared_error: 0.3784 - val_loss: 0.3831 - val_mean_squared_error: 0.3831\n",
            "Epoch 31/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.3803 - val_mean_squared_error: 0.3803\n",
            "Epoch 32/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3726 - mean_squared_error: 0.3726 - val_loss: 0.3776 - val_mean_squared_error: 0.3776\n",
            "Epoch 33/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.3699 - mean_squared_error: 0.3699 - val_loss: 0.3751 - val_mean_squared_error: 0.3751\n",
            "Epoch 34/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.3674 - mean_squared_error: 0.3674 - val_loss: 0.3727 - val_mean_squared_error: 0.3727\n",
            "Epoch 35/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3651 - mean_squared_error: 0.3651 - val_loss: 0.3705 - val_mean_squared_error: 0.3705\n",
            "Epoch 36/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3629 - mean_squared_error: 0.3629 - val_loss: 0.3684 - val_mean_squared_error: 0.3684\n",
            "Epoch 37/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3608 - mean_squared_error: 0.3608 - val_loss: 0.3664 - val_mean_squared_error: 0.3664\n",
            "Epoch 38/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3589 - mean_squared_error: 0.3589 - val_loss: 0.3645 - val_mean_squared_error: 0.3645\n",
            "Epoch 39/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3570 - mean_squared_error: 0.3570 - val_loss: 0.3627 - val_mean_squared_error: 0.3627\n",
            "Epoch 40/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3553 - mean_squared_error: 0.3553 - val_loss: 0.3611 - val_mean_squared_error: 0.3611\n",
            "Epoch 41/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3536 - mean_squared_error: 0.3536 - val_loss: 0.3594 - val_mean_squared_error: 0.3594\n",
            "Epoch 42/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3520 - mean_squared_error: 0.3520 - val_loss: 0.3579 - val_mean_squared_error: 0.3579\n",
            "Epoch 43/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3505 - mean_squared_error: 0.3505 - val_loss: 0.3564 - val_mean_squared_error: 0.3564\n",
            "Epoch 44/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3491 - mean_squared_error: 0.3491 - val_loss: 0.3550 - val_mean_squared_error: 0.3550\n",
            "Epoch 45/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3477 - mean_squared_error: 0.3477 - val_loss: 0.3537 - val_mean_squared_error: 0.3537\n",
            "Epoch 46/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3464 - mean_squared_error: 0.3464 - val_loss: 0.3524 - val_mean_squared_error: 0.3524\n",
            "Epoch 47/200\n",
            "129360/129360 [==============================] - 34s 263us/sample - loss: 0.3452 - mean_squared_error: 0.3452 - val_loss: 0.3512 - val_mean_squared_error: 0.3512\n",
            "Epoch 48/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3440 - mean_squared_error: 0.3440 - val_loss: 0.3500 - val_mean_squared_error: 0.3500\n",
            "Epoch 49/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3429 - mean_squared_error: 0.3429 - val_loss: 0.3490 - val_mean_squared_error: 0.3490\n",
            "Epoch 50/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3418 - mean_squared_error: 0.3418 - val_loss: 0.3478 - val_mean_squared_error: 0.3478\n",
            "Epoch 51/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3407 - mean_squared_error: 0.3407 - val_loss: 0.3468 - val_mean_squared_error: 0.3468\n",
            "Epoch 52/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3397 - mean_squared_error: 0.3397 - val_loss: 0.3460 - val_mean_squared_error: 0.3460\n",
            "Epoch 53/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3388 - mean_squared_error: 0.3388 - val_loss: 0.3449 - val_mean_squared_error: 0.3449\n",
            "Epoch 54/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3379 - mean_squared_error: 0.3379 - val_loss: 0.3441 - val_mean_squared_error: 0.3441\n",
            "Epoch 55/200\n",
            "129360/129360 [==============================] - 34s 262us/sample - loss: 0.3370 - mean_squared_error: 0.3370 - val_loss: 0.3432 - val_mean_squared_error: 0.3432\n",
            "Epoch 56/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3361 - mean_squared_error: 0.3361 - val_loss: 0.3425 - val_mean_squared_error: 0.3425\n",
            "Epoch 57/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3353 - mean_squared_error: 0.3353 - val_loss: 0.3416 - val_mean_squared_error: 0.3416\n",
            "Epoch 58/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3345 - mean_squared_error: 0.3345 - val_loss: 0.3408 - val_mean_squared_error: 0.3408\n",
            "Epoch 59/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3337 - mean_squared_error: 0.3337 - val_loss: 0.3400 - val_mean_squared_error: 0.3400\n",
            "Epoch 60/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3330 - mean_squared_error: 0.3330 - val_loss: 0.3393 - val_mean_squared_error: 0.3393\n",
            "Epoch 61/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3323 - mean_squared_error: 0.3323 - val_loss: 0.3386 - val_mean_squared_error: 0.3386\n",
            "Epoch 62/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3316 - mean_squared_error: 0.3316 - val_loss: 0.3379 - val_mean_squared_error: 0.3379\n",
            "Epoch 63/200\n",
            "129360/129360 [==============================] - 34s 267us/sample - loss: 0.3310 - mean_squared_error: 0.3310 - val_loss: 0.3373 - val_mean_squared_error: 0.3373\n",
            "Epoch 64/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3303 - mean_squared_error: 0.3303 - val_loss: 0.3366 - val_mean_squared_error: 0.3366\n",
            "Epoch 65/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3297 - mean_squared_error: 0.3297 - val_loss: 0.3360 - val_mean_squared_error: 0.3360\n",
            "Epoch 66/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3291 - mean_squared_error: 0.3291 - val_loss: 0.3355 - val_mean_squared_error: 0.3355\n",
            "Epoch 67/200\n",
            "129360/129360 [==============================] - 34s 267us/sample - loss: 0.3285 - mean_squared_error: 0.3285 - val_loss: 0.3349 - val_mean_squared_error: 0.3349\n",
            "Epoch 68/200\n",
            "129360/129360 [==============================] - 34s 267us/sample - loss: 0.3279 - mean_squared_error: 0.3279 - val_loss: 0.3345 - val_mean_squared_error: 0.3345\n",
            "Epoch 69/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3273 - mean_squared_error: 0.3273 - val_loss: 0.3339 - val_mean_squared_error: 0.3339\n",
            "Epoch 70/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3268 - mean_squared_error: 0.3268 - val_loss: 0.3332 - val_mean_squared_error: 0.3332\n",
            "Epoch 71/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3263 - mean_squared_error: 0.3263 - val_loss: 0.3328 - val_mean_squared_error: 0.3328\n",
            "Epoch 72/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3258 - mean_squared_error: 0.3258 - val_loss: 0.3324 - val_mean_squared_error: 0.3324\n",
            "Epoch 73/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3253 - mean_squared_error: 0.3253 - val_loss: 0.3318 - val_mean_squared_error: 0.3318\n",
            "Epoch 74/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3248 - mean_squared_error: 0.3248 - val_loss: 0.3313 - val_mean_squared_error: 0.3313\n",
            "Epoch 75/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.3308 - val_mean_squared_error: 0.3308\n",
            "Epoch 76/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3238 - mean_squared_error: 0.3238 - val_loss: 0.3304 - val_mean_squared_error: 0.3304\n",
            "Epoch 77/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3234 - mean_squared_error: 0.3234 - val_loss: 0.3299 - val_mean_squared_error: 0.3299\n",
            "Epoch 78/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3229 - mean_squared_error: 0.3229 - val_loss: 0.3295 - val_mean_squared_error: 0.3295\n",
            "Epoch 79/200\n",
            "129360/129360 [==============================] - 34s 267us/sample - loss: 0.3225 - mean_squared_error: 0.3225 - val_loss: 0.3291 - val_mean_squared_error: 0.3291\n",
            "Epoch 80/200\n",
            "129360/129360 [==============================] - 35s 271us/sample - loss: 0.3221 - mean_squared_error: 0.3221 - val_loss: 0.3286 - val_mean_squared_error: 0.3286\n",
            "Epoch 81/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3216 - mean_squared_error: 0.3216 - val_loss: 0.3283 - val_mean_squared_error: 0.3283\n",
            "Epoch 82/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3212 - mean_squared_error: 0.3212 - val_loss: 0.3278 - val_mean_squared_error: 0.3278\n",
            "Epoch 83/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3208 - mean_squared_error: 0.3208 - val_loss: 0.3274 - val_mean_squared_error: 0.3274\n",
            "Epoch 84/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3204 - mean_squared_error: 0.3204 - val_loss: 0.3271 - val_mean_squared_error: 0.3271\n",
            "Epoch 85/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3201 - mean_squared_error: 0.3201 - val_loss: 0.3267 - val_mean_squared_error: 0.3267\n",
            "Epoch 86/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.3264 - val_mean_squared_error: 0.3264\n",
            "Epoch 87/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3193 - mean_squared_error: 0.3193 - val_loss: 0.3260 - val_mean_squared_error: 0.3260\n",
            "Epoch 88/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.3190 - mean_squared_error: 0.3190 - val_loss: 0.3258 - val_mean_squared_error: 0.3258\n",
            "Epoch 89/200\n",
            "129360/129360 [==============================] - 35s 272us/sample - loss: 0.3186 - mean_squared_error: 0.3186 - val_loss: 0.3253 - val_mean_squared_error: 0.3253\n",
            "Epoch 90/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.3183 - mean_squared_error: 0.3183 - val_loss: 0.3251 - val_mean_squared_error: 0.3251\n",
            "Epoch 91/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3179 - mean_squared_error: 0.3179 - val_loss: 0.3247 - val_mean_squared_error: 0.3247\n",
            "Epoch 92/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3176 - mean_squared_error: 0.3176 - val_loss: 0.3244 - val_mean_squared_error: 0.3244\n",
            "Epoch 93/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3172 - mean_squared_error: 0.3172 - val_loss: 0.3240 - val_mean_squared_error: 0.3240\n",
            "Epoch 94/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3169 - mean_squared_error: 0.3169 - val_loss: 0.3237 - val_mean_squared_error: 0.3237\n",
            "Epoch 95/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.3166 - mean_squared_error: 0.3166 - val_loss: 0.3235 - val_mean_squared_error: 0.3235\n",
            "Epoch 96/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3163 - mean_squared_error: 0.3163 - val_loss: 0.3231 - val_mean_squared_error: 0.3231\n",
            "Epoch 97/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3160 - mean_squared_error: 0.3160 - val_loss: 0.3228 - val_mean_squared_error: 0.3228\n",
            "Epoch 98/200\n",
            "129360/129360 [==============================] - 35s 273us/sample - loss: 0.3157 - mean_squared_error: 0.3157 - val_loss: 0.3226 - val_mean_squared_error: 0.3226\n",
            "Epoch 99/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3154 - mean_squared_error: 0.3154 - val_loss: 0.3222 - val_mean_squared_error: 0.3222\n",
            "Epoch 100/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3151 - mean_squared_error: 0.3151 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
            "Epoch 101/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3149 - mean_squared_error: 0.3149 - val_loss: 0.3218 - val_mean_squared_error: 0.3218\n",
            "Epoch 102/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3146 - mean_squared_error: 0.3146 - val_loss: 0.3216 - val_mean_squared_error: 0.3216\n",
            "Epoch 103/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3143 - mean_squared_error: 0.3143 - val_loss: 0.3214 - val_mean_squared_error: 0.3214\n",
            "Epoch 104/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3141 - mean_squared_error: 0.3141 - val_loss: 0.3211 - val_mean_squared_error: 0.3211\n",
            "Epoch 105/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3138 - mean_squared_error: 0.3138 - val_loss: 0.3208 - val_mean_squared_error: 0.3208\n",
            "Epoch 106/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3136 - mean_squared_error: 0.3136 - val_loss: 0.3205 - val_mean_squared_error: 0.3205\n",
            "Epoch 107/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3133 - mean_squared_error: 0.3133 - val_loss: 0.3204 - val_mean_squared_error: 0.3204\n",
            "Epoch 108/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3131 - mean_squared_error: 0.3131 - val_loss: 0.3201 - val_mean_squared_error: 0.3201\n",
            "Epoch 109/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3128 - mean_squared_error: 0.3128 - val_loss: 0.3199 - val_mean_squared_error: 0.3199\n",
            "Epoch 110/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3126 - mean_squared_error: 0.3126 - val_loss: 0.3196 - val_mean_squared_error: 0.3196\n",
            "Epoch 111/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3124 - mean_squared_error: 0.3124 - val_loss: 0.3194 - val_mean_squared_error: 0.3194\n",
            "Epoch 112/200\n",
            "129360/129360 [==============================] - 34s 263us/sample - loss: 0.3121 - mean_squared_error: 0.3121 - val_loss: 0.3193 - val_mean_squared_error: 0.3193\n",
            "Epoch 113/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - val_loss: 0.3190 - val_mean_squared_error: 0.3190\n",
            "Epoch 114/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3117 - mean_squared_error: 0.3117 - val_loss: 0.3188 - val_mean_squared_error: 0.3188\n",
            "Epoch 115/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3115 - mean_squared_error: 0.3115 - val_loss: 0.3186 - val_mean_squared_error: 0.3186\n",
            "Epoch 116/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3113 - mean_squared_error: 0.3113 - val_loss: 0.3185 - val_mean_squared_error: 0.3185\n",
            "Epoch 117/200\n",
            "129360/129360 [==============================] - 34s 264us/sample - loss: 0.3111 - mean_squared_error: 0.3111 - val_loss: 0.3183 - val_mean_squared_error: 0.3183\n",
            "Epoch 118/200\n",
            "129360/129360 [==============================] - 34s 267us/sample - loss: 0.3109 - mean_squared_error: 0.3109 - val_loss: 0.3182 - val_mean_squared_error: 0.3182\n",
            "Epoch 119/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3107 - mean_squared_error: 0.3107 - val_loss: 0.3178 - val_mean_squared_error: 0.3178\n",
            "Epoch 120/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3105 - mean_squared_error: 0.3105 - val_loss: 0.3177 - val_mean_squared_error: 0.3177\n",
            "Epoch 121/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3103 - mean_squared_error: 0.3103 - val_loss: 0.3175 - val_mean_squared_error: 0.3175\n",
            "Epoch 122/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3101 - mean_squared_error: 0.3101 - val_loss: 0.3174 - val_mean_squared_error: 0.3174\n",
            "Epoch 123/200\n",
            "129360/129360 [==============================] - 34s 266us/sample - loss: 0.3099 - mean_squared_error: 0.3099 - val_loss: 0.3171 - val_mean_squared_error: 0.3171\n",
            "Epoch 124/200\n",
            "129360/129360 [==============================] - 34s 265us/sample - loss: 0.3097 - mean_squared_error: 0.3097 - val_loss: 0.3169 - val_mean_squared_error: 0.3169\n",
            "Epoch 125/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3095 - mean_squared_error: 0.3095 - val_loss: 0.3168 - val_mean_squared_error: 0.3168\n",
            "Epoch 126/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3093 - mean_squared_error: 0.3093 - val_loss: 0.3168 - val_mean_squared_error: 0.3168\n",
            "Epoch 127/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.3092 - mean_squared_error: 0.3092 - val_loss: 0.3165 - val_mean_squared_error: 0.3165\n",
            "Epoch 128/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3090 - mean_squared_error: 0.3090 - val_loss: 0.3164 - val_mean_squared_error: 0.3164\n",
            "Epoch 129/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3088 - mean_squared_error: 0.3088 - val_loss: 0.3162 - val_mean_squared_error: 0.3162\n",
            "Epoch 130/200\n",
            "129360/129360 [==============================] - 35s 267us/sample - loss: 0.3087 - mean_squared_error: 0.3087 - val_loss: 0.3159 - val_mean_squared_error: 0.3159\n",
            "Epoch 131/200\n",
            "129360/129360 [==============================] - 35s 268us/sample - loss: 0.3085 - mean_squared_error: 0.3085 - val_loss: 0.3159 - val_mean_squared_error: 0.3159\n",
            "Epoch 132/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3083 - mean_squared_error: 0.3083 - val_loss: 0.3158 - val_mean_squared_error: 0.3158\n",
            "Epoch 133/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3082 - mean_squared_error: 0.3082 - val_loss: 0.3156 - val_mean_squared_error: 0.3156\n",
            "Epoch 134/200\n",
            "129360/129360 [==============================] - 35s 270us/sample - loss: 0.3080 - mean_squared_error: 0.3080 - val_loss: 0.3153 - val_mean_squared_error: 0.3153\n",
            "Epoch 135/200\n",
            "129360/129360 [==============================] - 35s 269us/sample - loss: 0.3079 - mean_squared_error: 0.3079 - val_loss: 0.3153 - val_mean_squared_error: 0.3153\n",
            "Epoch 136/200\n",
            " 80896/129360 [=================>............] - ETA: 12s - loss: 0.3073 - mean_squared_error: 0.3073"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V10is7e7GOtf",
        "colab_type": "code",
        "outputId": "7899e516-7622-4513-9191-378ce02f2157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = model.predict(test_X, verbose  = 1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15960/15960 [==============================] - 24s 2ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y0-Bs6g_IQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_correlation(true, pred):\n",
        "    corr_coef = np.corrcoef(true, pred)[0, 1]\n",
        "    return corr_coef \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp-14YbbXL1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dc2dda2-c286-4caa-828b-458a0e444ced"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15960, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lOSkjCE_K7l",
        "colab_type": "code",
        "outputId": "5ba88669-af74-49ac-857e-6bf4c8543dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "compute_correlation(y_test, predictions)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7774253406510199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFap89N7r1nJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_correlation(electi, true, pred):\n",
        "    l = []\n",
        "    for i in range(true.shape[0]):\n",
        "        l.append(compute_correlation(true[i, :], pred[i,: ]))\n",
        "    return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zk1aXdzr8zD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = list_correlation(electi, y_test, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nsC5T2uBjwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3534c75a-77bf-4bac-8d69-384a189a96cc"
      },
      "source": [
        "k"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7995549463546774,\n",
              " 0.759637157211194,\n",
              " 0.7336911480045082,\n",
              " 0.8086965598478387,\n",
              " 0.7090263577977994,\n",
              " 0.7249174334561422,\n",
              " 0.6762698662668182,\n",
              " 0.716898239641389,\n",
              " 0.7163485546063122,\n",
              " 0.8174591702587054,\n",
              " 0.6930340605394494,\n",
              " 0.7613989928596746,\n",
              " 0.618210651416681,\n",
              " 0.4972294865034221,\n",
              " 0.5411813455846635,\n",
              " 0.5837259524305457,\n",
              " 0.8462300399454272,\n",
              " 0.7424514778325689,\n",
              " 0.8228628811084799,\n",
              " 0.780368501537682,\n",
              " 0.7766337997390456,\n",
              " 0.8164661601631938,\n",
              " 0.8264447365105794,\n",
              " 0.74527354607218,\n",
              " 0.7344800592013538,\n",
              " 0.5125666363016317,\n",
              " 0.9050190876121972,\n",
              " 0.7990965976094256,\n",
              " 0.8466088262163699,\n",
              " 0.843266488395759,\n",
              " 0.5590622197363528,\n",
              " 0.5670767764320032,\n",
              " 0.6595339437851437,\n",
              " 0.7951144482175806,\n",
              " 0.9175218941539207,\n",
              " 0.9346511621745097,\n",
              " 0.7885891948452941,\n",
              " 0.8816666510102933,\n",
              " 0.8811053361838669,\n",
              " 0.8688472868303797,\n",
              " 0.8305851353673651,\n",
              " 0.5592305575711873,\n",
              " 0.7442231679786143,\n",
              " 0.8169494266890649,\n",
              " 0.866000626395243,\n",
              " 0.8381508076141517,\n",
              " 0.848029958259288,\n",
              " 0.7155115167534327,\n",
              " 0.6126896303184807,\n",
              " 0.6014172662748793,\n",
              " 0.644133745291718,\n",
              " 0.8580115067746474,\n",
              " 0.7640809694368534,\n",
              " 0.5183156090348953,\n",
              " 0.597620390515203,\n",
              " 0.6910035092119212,\n",
              " 0.5510751109823165,\n",
              " 0.7861377118210818,\n",
              " 0.858903907662911,\n",
              " 0.775301853416771,\n",
              " 0.4259000945842682,\n",
              " 0.8516283763201032,\n",
              " 0.8815681779230382,\n",
              " 0.7849858847429693,\n",
              " 0.796255471062536,\n",
              " 0.8299838905239663,\n",
              " 0.7132624188639799,\n",
              " 0.7742316283716046,\n",
              " 0.719372675053733,\n",
              " 0.7102914583179208,\n",
              " 0.7133801227654755,\n",
              " 0.7959410463449315,\n",
              " 0.698857843671171,\n",
              " 0.7278373573841588,\n",
              " 0.6259904207004854,\n",
              " 0.7558660488574755,\n",
              " 0.7484618228757274,\n",
              " 0.8809770770796005,\n",
              " 0.836769310182883,\n",
              " 0.8762999168505745,\n",
              " 0.7890908535894231,\n",
              " 0.8514492483114614,\n",
              " 0.7137925458172144,\n",
              " 0.551724565059663,\n",
              " 0.7973793273065755,\n",
              " 0.8758725567757562,\n",
              " 0.8358608195839746,\n",
              " 0.7235576471290524,\n",
              " 0.8722728297496407,\n",
              " 0.6848372763351255,\n",
              " 0.8697427787212608,\n",
              " 0.7365929384496933,\n",
              " 0.5091235917613344,\n",
              " 0.719763475547879,\n",
              " 0.6217595850029818,\n",
              " 0.6087964646029375,\n",
              " 0.7520444242674725,\n",
              " 0.7821125747542522,\n",
              " 0.6289319013985175,\n",
              " 0.630558603258659,\n",
              " 0.8730758474308479,\n",
              " 0.7812642220396155,\n",
              " 0.7427922938488278,\n",
              " 0.649518839766906,\n",
              " 0.7586817191876347,\n",
              " 0.7310101187188051,\n",
              " 0.5967828292590893,\n",
              " 0.5625856646229899,\n",
              " 0.8188770333433514,\n",
              " 0.8133328916153288,\n",
              " 0.8407216231846184,\n",
              " 0.8083070779647558,\n",
              " 0.8904291530549661,\n",
              " 0.7872705589012183,\n",
              " 0.808029634286769,\n",
              " 0.5606304501744693,\n",
              " 0.918067386753542,\n",
              " 0.9520903666365226,\n",
              " 0.8753017957421472,\n",
              " 0.5560254257972925,\n",
              " 0.6760084639519601,\n",
              " 0.7759449357467528,\n",
              " 0.8447215040267056,\n",
              " 0.8986280950976915,\n",
              " 0.7784516859664213,\n",
              " 0.6962812906249145,\n",
              " 0.5670621058420323,\n",
              " 0.7945937134205114,\n",
              " 0.7999464752116816,\n",
              " 0.8354265411007297,\n",
              " 0.7422323938351718,\n",
              " 0.9208475313359639,\n",
              " 0.9182120304228798,\n",
              " 0.7394896470525764,\n",
              " 0.5950180161685498,\n",
              " 0.5408394757013757,\n",
              " 0.9414172053260049,\n",
              " 0.846591047172994,\n",
              " 0.7876477827808963,\n",
              " 0.7265599550471253,\n",
              " 0.7772032164147753,\n",
              " 0.856985844871297,\n",
              " 0.543351162884326,\n",
              " 0.8385196319710195,\n",
              " 0.8167301626817384,\n",
              " 0.9430185798269711,\n",
              " 0.9164640459625226,\n",
              " 0.9559541061517993,\n",
              " 0.8707236946741614,\n",
              " 0.7050693176195282,\n",
              " 0.7274364253185562,\n",
              " 0.8618654142350717,\n",
              " 0.8428416780097157,\n",
              " 0.4210092530233736,\n",
              " 0.6467653474501689,\n",
              " 0.8461590380974435,\n",
              " 0.7229147076773321,\n",
              " 0.8526519984222585,\n",
              " 0.7629108652710238,\n",
              " 0.8129550263558356,\n",
              " 0.6765368880175646,\n",
              " 0.7037897812491031,\n",
              " 0.8219246533116614,\n",
              " 0.7477269498206212,\n",
              " 0.6248768601413853,\n",
              " 0.6922079290795891,\n",
              " 0.6027142723123176,\n",
              " 0.3463400291936111,\n",
              " 0.40981226484492833,\n",
              " 0.7465798778961483,\n",
              " 0.8137096736413064,\n",
              " 0.7326788452464178,\n",
              " 0.8495853837615933,\n",
              " 0.7923895966909037,\n",
              " 0.8904106542221585,\n",
              " 0.6761391213924208,\n",
              " 0.8074750397049605,\n",
              " 0.7882551637153433,\n",
              " 0.8529228323541154,\n",
              " 0.8439493293191102,\n",
              " 0.8172410562326524,\n",
              " 0.8858689550578107,\n",
              " 0.8898439636801149,\n",
              " 0.7036469169771494,\n",
              " 0.6339559112815145,\n",
              " 0.9161322845287949,\n",
              " 0.7219020011648846,\n",
              " 0.8173650945723644,\n",
              " 0.7668644754785672,\n",
              " 0.755294929402,\n",
              " 0.6945752252869484,\n",
              " 0.6121513968175444,\n",
              " 0.8449047257880975,\n",
              " 0.8187414780930957,\n",
              " 0.753194387260714,\n",
              " 0.8645943778842727,\n",
              " 0.8963646112750112,\n",
              " 0.8343733757058364,\n",
              " 0.8267183811473681,\n",
              " 0.8116599764622368,\n",
              " 0.8751387335180354,\n",
              " 0.8457298505478091,\n",
              " 0.5568482528082715,\n",
              " 0.7514379966135817,\n",
              " 0.7496346042725971,\n",
              " 0.8198103263176499,\n",
              " 0.9086638873040965,\n",
              " 0.8175026816603482,\n",
              " 0.8147483487961497,\n",
              " 0.9108774446222458,\n",
              " 0.8191803248135102,\n",
              " 0.5009935664511551,\n",
              " 0.8463998546003159,\n",
              " 0.87569435751544,\n",
              " 0.8463532648684591,\n",
              " 0.8485323967889633,\n",
              " 0.875950990021605,\n",
              " 0.831485944234166,\n",
              " 0.8798513693438309,\n",
              " 0.8103426358411613,\n",
              " 0.7556382513180476,\n",
              " 0.8076384059729211,\n",
              " 0.8561051056919781,\n",
              " 0.8356182241401446,\n",
              " 0.7596503936376084,\n",
              " 0.8699214383346584,\n",
              " 0.8449990176442673,\n",
              " 0.8579471935640758,\n",
              " 0.795047215167164,\n",
              " 0.7044666929974159,\n",
              " 0.6653209195126073,\n",
              " 0.7796587250127173,\n",
              " 0.7628525662878295,\n",
              " 0.6173701472980104,\n",
              " 0.7423520534399626,\n",
              " 0.8155741515326171,\n",
              " 0.7529354727335122,\n",
              " 0.7133765076850628,\n",
              " 0.6799080088777962,\n",
              " 0.6088357849510935,\n",
              " 0.7887442038017626,\n",
              " 0.849970180434103,\n",
              " 0.876422941131629,\n",
              " 0.9228660462289617,\n",
              " 0.8032884919246362,\n",
              " 0.7901724525133559,\n",
              " 0.9084205663067023,\n",
              " 0.8705334583406494,\n",
              " 0.823659733083232,\n",
              " 0.5625851784561282,\n",
              " 0.7282735578395936,\n",
              " 0.7878746316837726,\n",
              " 0.7007288403770823,\n",
              " 0.820145192302471,\n",
              " 0.6207819744583933,\n",
              " 0.6011941845351789,\n",
              " 0.9443732033681366,\n",
              " 0.8798531931462709,\n",
              " 0.8543132521702277,\n",
              " 0.881895570174182,\n",
              " 0.8094814482485637,\n",
              " 0.8953673067900412,\n",
              " 0.8116543851437918,\n",
              " 0.737014772440833,\n",
              " 0.6648750353602101,\n",
              " 0.7844743483189354,\n",
              " 0.7195932668146959,\n",
              " 0.8093692494579114,\n",
              " 0.8283204873988272,\n",
              " 0.8174297306437969,\n",
              " 0.6403998510248998,\n",
              " 0.7326723129702846,\n",
              " 0.6356671294083908,\n",
              " 0.5955416499656293,\n",
              " 0.6410008521923273,\n",
              " 0.7953272921640001,\n",
              " 0.7750742174499956,\n",
              " 0.6419819150086199,\n",
              " 0.7682294770722581,\n",
              " 0.5387295336678258,\n",
              " 0.4847152569241734,\n",
              " 0.5131223437430548,\n",
              " 0.5528552050273231,\n",
              " 0.6633529365185675,\n",
              " 0.782784109861891,\n",
              " 0.917569242003644,\n",
              " 0.9178592613487315,\n",
              " 0.889394184599734,\n",
              " 0.892708599748319,\n",
              " 0.8257122720727516,\n",
              " 0.8237143139174411,\n",
              " 0.8052335815496755,\n",
              " 0.8108945832676901,\n",
              " 0.5165090341535802,\n",
              " 0.7623484771740863,\n",
              " 0.7360006670071773,\n",
              " 0.8229290851187893,\n",
              " 0.8118121225006683,\n",
              " 0.8505295418662594,\n",
              " 0.8385995931057867,\n",
              " 0.48567632958114026,\n",
              " 0.43329042744275553,\n",
              " 0.7585809021238247,\n",
              " 0.7779232139792523,\n",
              " 0.3629737699070334,\n",
              " 0.4658508947465194,\n",
              " 0.5211889928581592,\n",
              " 0.6494816356238235,\n",
              " 0.8619754473794213,\n",
              " 0.8752468416415177,\n",
              " 0.8327788279845826,\n",
              " 0.7959008382501814,\n",
              " 0.686813941770492,\n",
              " 0.7129479611370436,\n",
              " 0.6771794744211935,\n",
              " 0.5010511640494525,\n",
              " 0.7610367023088269,\n",
              " 0.8161950607383771,\n",
              " 0.8969368472969514,\n",
              " 0.8440930297982745,\n",
              " 0.8596258291509278,\n",
              " 0.8347842379443589,\n",
              " 0.8133401599623644,\n",
              " 0.8622416566992751,\n",
              " 0.8956234196506908,\n",
              " 0.30488322385606115,\n",
              " 0.34892882397370956,\n",
              " 0.47509271137926257,\n",
              " 0.7929100169086509,\n",
              " 0.8990616164223327,\n",
              " 0.7260941383282342,\n",
              " 0.6086479881405776,\n",
              " 0.49422698644286195,\n",
              " 0.595780136166165,\n",
              " 0.808921258776694,\n",
              " 0.777690594250755,\n",
              " 0.7600188720579345,\n",
              " 0.6806955559858072,\n",
              " 0.8104944966834221,\n",
              " 0.6137691898047123,\n",
              " 0.7051798461401146,\n",
              " 0.723595366768428,\n",
              " 0.4509608264337383,\n",
              " 0.8729787996046775,\n",
              " 0.7554628004894357,\n",
              " 0.7590567367870876,\n",
              " 0.6198263757533101,\n",
              " 0.5900588298615798,\n",
              " 0.8120111011927694,\n",
              " 0.9074037232007184,\n",
              " 0.8481905005192696,\n",
              " 0.8363028133531926,\n",
              " 0.7866460564597003,\n",
              " 0.7981347700316087,\n",
              " 0.3896188355708849,\n",
              " 0.8057530361554908,\n",
              " 0.591306970655644,\n",
              " 0.8055604417300444,\n",
              " 0.8580588083432693,\n",
              " 0.704973221962918,\n",
              " 0.856203007237915,\n",
              " 0.8368485359864033,\n",
              " 0.5832936538889741,\n",
              " 0.7780872144824811,\n",
              " 0.8859260819132905,\n",
              " 0.8272554345897908,\n",
              " 0.8233605962914285,\n",
              " 0.7029890501153755,\n",
              " 0.6081745165031872,\n",
              " 0.9207931679657646,\n",
              " 0.9013734692875192,\n",
              " 0.8797395460060916,\n",
              " 0.9202242322015699,\n",
              " 0.8873136341713099,\n",
              " 0.924464986075407,\n",
              " 0.9010765508887533,\n",
              " 0.8680643965336471,\n",
              " 0.8454000760162768,\n",
              " 0.6967176297772726,\n",
              " 0.7596330587942963,\n",
              " 0.8539613059058402,\n",
              " 0.9092898012520069,\n",
              " 0.8739832467364099,\n",
              " 0.7244682403311573,\n",
              " 0.6211429525204484,\n",
              " 0.8633528933913027,\n",
              " 0.6838062821401582,\n",
              " 0.8629754827303268,\n",
              " 0.8188333921499241,\n",
              " 0.7139684179403485,\n",
              " 0.7052867260050686,\n",
              " 0.7458328891125963,\n",
              " 0.8122916957867464,\n",
              " 0.7713110473437564,\n",
              " 0.7758467010266139,\n",
              " 0.6330729948752479,\n",
              " 0.9110824666961624,\n",
              " 0.8478885547563291,\n",
              " 0.8487761261653644,\n",
              " 0.8886324203506591,\n",
              " 0.8515852324050054,\n",
              " 0.6279698270835917,\n",
              " 0.7017443890572161,\n",
              " 0.8401321581562109,\n",
              " 0.8003656413224818,\n",
              " 0.7109112183343855,\n",
              " 0.7555826825236605,\n",
              " 0.6260708930330827,\n",
              " 0.8539774880907445,\n",
              " 0.7940970861809062,\n",
              " 0.5507425253460144,\n",
              " 0.6873110639768414,\n",
              " 0.883169707162034,\n",
              " 0.826357348252867,\n",
              " 0.8151385191113987,\n",
              " 0.7114849287356109,\n",
              " 0.8046897784561695,\n",
              " 0.6436658536032085,\n",
              " 0.6504689797987377,\n",
              " 0.7566203637929564,\n",
              " 0.8912769440646505,\n",
              " 0.8840352986815081,\n",
              " 0.9334937128032966,\n",
              " 0.8610521292048425,\n",
              " 0.9333281319392857,\n",
              " 0.8958078801651426,\n",
              " 0.9344890867011952,\n",
              " 0.9610716638787685,\n",
              " 0.91600205063826,\n",
              " 0.8798758984202197,\n",
              " 0.9242912057154395,\n",
              " 0.8245961337772285,\n",
              " 0.8963753486175833,\n",
              " 0.7153033779603478,\n",
              " 0.8060359023041349,\n",
              " 0.8269673627822118,\n",
              " 0.6227244832279596,\n",
              " 0.8663977695446953,\n",
              " 0.8987337954770567,\n",
              " 0.9084367981363232,\n",
              " 0.8803205993572262,\n",
              " 0.8531048799726905,\n",
              " 0.7742773806839335,\n",
              " 0.7873943449390814,\n",
              " 0.8619512047333804,\n",
              " 0.8079273792437127,\n",
              " 0.8813088351430856,\n",
              " 0.8248125900514474,\n",
              " 0.889122040749242,\n",
              " 0.8052102780811685,\n",
              " 0.8754583934144732,\n",
              " 0.794861414269178,\n",
              " 0.8390547897726838,\n",
              " 0.6497319718491567,\n",
              " 0.8948646023737711,\n",
              " 0.6559814187666073,\n",
              " 0.7846972294051713,\n",
              " 0.6081265802262391,\n",
              " 0.7497573278394196,\n",
              " 0.8134029279372844,\n",
              " 0.8227703927276679,\n",
              " 0.7120506785606333,\n",
              " 0.696180051021761,\n",
              " 0.8326999614061741,\n",
              " 0.7006399022968113,\n",
              " 0.8564586853695304,\n",
              " 0.8505463082092809,\n",
              " 0.8100160992073824,\n",
              " 0.8082284931607507,\n",
              " 0.7197974529720373,\n",
              " 0.730162736206758,\n",
              " 0.8335785265841615,\n",
              " 0.8536413645553592,\n",
              " 0.5370707193186147,\n",
              " 0.6409438761088141,\n",
              " 0.6783820906747122,\n",
              " 0.7064895460778746,\n",
              " 0.8060673951824038,\n",
              " 0.8170838325518065,\n",
              " 0.8639285207486254,\n",
              " 0.5368347443338317,\n",
              " 0.5936735935617137,\n",
              " 0.5993242618269001,\n",
              " 0.8485418835000439,\n",
              " 0.855502349426822,\n",
              " 0.5576769456046449,\n",
              " 0.9120069150000781,\n",
              " 0.882219084898981,\n",
              " 0.7699592718187781,\n",
              " 0.8248042128540083,\n",
              " 0.8040004840264895,\n",
              " 0.8387439959632986,\n",
              " 0.4035547509930936,\n",
              " 0.7099560369979612,\n",
              " 0.6147513968105981,\n",
              " 0.7251480502518459,\n",
              " 0.8280192554356705,\n",
              " 0.8360340790914426,\n",
              " 0.8237228398325848,\n",
              " 0.890773115301952,\n",
              " 0.8987797862136425,\n",
              " 0.9160071496844516,\n",
              " 0.9336010325571774,\n",
              " 0.7766039049620784,\n",
              " 0.8599497867197187,\n",
              " 0.8266541136734787,\n",
              " 0.9101778069224394,\n",
              " 0.9062289982387179,\n",
              " 0.690444352911952,\n",
              " 0.7597657089370903,\n",
              " 0.5822272317547524,\n",
              " 0.6333082201754751,\n",
              " 0.34816231008087223,\n",
              " 0.5816806083783429,\n",
              " 0.852531713812872,\n",
              " 0.7536000793612904,\n",
              " 0.515690450439956,\n",
              " 0.6578675683751459,\n",
              " 0.7595152147572186,\n",
              " 0.8985944550198864,\n",
              " 0.7862028910691227,\n",
              " 0.8123051950872178,\n",
              " 0.8430417457769623,\n",
              " 0.7174243643043566,\n",
              " 0.7877633650925001,\n",
              " 0.6649794612971732,\n",
              " 0.5784754883591942,\n",
              " 0.6893467624935239,\n",
              " 0.6919903108073505,\n",
              " 0.7993694602758604,\n",
              " 0.6545257360464056,\n",
              " 0.5747666461766437,\n",
              " 0.8326639655159154,\n",
              " 0.824993019670308,\n",
              " 0.769556993532165,\n",
              " 0.8327845718714293,\n",
              " 0.8545900939248053,\n",
              " 0.8497107281799914,\n",
              " 0.7045426067540702,\n",
              " 0.8868736799071806,\n",
              " 0.8093287624743729,\n",
              " 0.5969242825272826,\n",
              " 0.8954998795334316,\n",
              " 0.8694501365138221,\n",
              " 0.9179225498559376,\n",
              " 0.920574715610167,\n",
              " 0.791483184267537,\n",
              " 0.8163782480667351,\n",
              " 0.7451335449515555,\n",
              " 0.8871552301147423,\n",
              " 0.8570493107966153,\n",
              " 0.8308267874698697,\n",
              " 0.7566431248587648,\n",
              " 0.6859219411709273,\n",
              " 0.6262267649787978,\n",
              " 0.40727609149338867,\n",
              " 0.6929037411303701,\n",
              " 0.6908896277966741,\n",
              " 0.8605393384259596,\n",
              " 0.9140238635123925,\n",
              " 0.9370481221709281,\n",
              " 0.9113631100362852,\n",
              " 0.7626755079702925,\n",
              " 0.8131738908979339,\n",
              " 0.8818540704619398,\n",
              " 0.9539295975829686,\n",
              " 0.9569413484809827,\n",
              " 0.942576104729606,\n",
              " 0.8477453581371819,\n",
              " 0.8681554867990849,\n",
              " 0.7950291618586571,\n",
              " 0.8699270457467376,\n",
              " 0.841376977108068,\n",
              " 0.9593148463061728,\n",
              " 0.7718489619403237,\n",
              " 0.905210050251253,\n",
              " 0.8370964639178377,\n",
              " 0.6920488717961273,\n",
              " 0.5893062521715617,\n",
              " 0.9406348500697662,\n",
              " 0.9375420005125605,\n",
              " 0.8975464435736841,\n",
              " 0.8140083118987202,\n",
              " 0.9061774802951553,\n",
              " 0.9371238894174919,\n",
              " 0.8266024154323669,\n",
              " 0.782569732410736,\n",
              " 0.7346080081363218,\n",
              " 0.8979815980560669,\n",
              " 0.8844713034215578,\n",
              " 0.9701602792159328,\n",
              " 0.9313810134761994,\n",
              " 0.9244046709694206,\n",
              " 0.9473177141206989,\n",
              " 0.7738987763232619,\n",
              " 0.867177635285417,\n",
              " 0.9513456717321692,\n",
              " 0.8542671165644742,\n",
              " 0.9025516339694484,\n",
              " 0.8052173082219075,\n",
              " 0.7808132560145089,\n",
              " 0.8130191167886937,\n",
              " 0.681399368448418,\n",
              " 0.7672860249596051,\n",
              " 0.8556085982494301,\n",
              " 0.9633317559019442,\n",
              " 0.9598810509356287,\n",
              " 0.9139872636872111,\n",
              " 0.877365693083777,\n",
              " 0.8894077148266551,\n",
              " 0.8743555465195656,\n",
              " 0.9493325556905601,\n",
              " 0.9166927939448929,\n",
              " 0.741558639171843,\n",
              " 0.9271263629416162,\n",
              " 0.8866563296708598,\n",
              " 0.878657793649388,\n",
              " 0.8489206540298148,\n",
              " 0.8315619980487555,\n",
              " 0.9120375773820878,\n",
              " 0.9118937351512687,\n",
              " 0.8383850610554522,\n",
              " 0.908655794897037,\n",
              " 0.9113901561301206,\n",
              " 0.9056157536922856,\n",
              " 0.880265517086695,\n",
              " 0.8926562922099599,\n",
              " 0.7736495352464589,\n",
              " 0.8446932545411391,\n",
              " 0.6969239566808396,\n",
              " 0.6652649143795091,\n",
              " 0.8648397870968537,\n",
              " 0.8795965857820743,\n",
              " 0.7677660982581123,\n",
              " 0.6157470790438603,\n",
              " 0.8690181254154136,\n",
              " 0.8081624181871195,\n",
              " 0.7535131546852739,\n",
              " 0.6788124946198216,\n",
              " 0.5118856038621199,\n",
              " 0.6324257277668089,\n",
              " 0.8525027164969093,\n",
              " 0.7757933763452821,\n",
              " 0.8592396991262767,\n",
              " 0.6503892159973161,\n",
              " 0.4994018029426835,\n",
              " 0.8888323848097547,\n",
              " 0.9145092133225592,\n",
              " 0.9584726932340193,\n",
              " 0.975594737712886,\n",
              " 0.8784303704580756,\n",
              " 0.8608095504106291,\n",
              " 0.8295980058347285,\n",
              " 0.8201972380247454,\n",
              " 0.8359073962799483,\n",
              " 0.9105964534664779,\n",
              " 0.8794750041739561,\n",
              " 0.7550227066113822,\n",
              " 0.9136125957651792,\n",
              " 0.8292376387969788,\n",
              " 0.8335694016628544,\n",
              " 0.860004194391771,\n",
              " 0.902222568901246,\n",
              " 0.7971064082378325,\n",
              " 0.8178920228334138,\n",
              " 0.7281083635916572,\n",
              " 0.717118002383126,\n",
              " 0.7393889670282736,\n",
              " 0.815884496521394,\n",
              " 0.8613150354965,\n",
              " 0.7516993312469847,\n",
              " 0.6326689289895125,\n",
              " 0.840870818931844,\n",
              " 0.7611290684155334,\n",
              " 0.6406611681609156,\n",
              " 0.7520198037521693,\n",
              " 0.8219711659812675,\n",
              " 0.8765080171454431,\n",
              " 0.9236142991645466,\n",
              " 0.9632574123285974,\n",
              " 0.9153197150412437,\n",
              " 0.9166274659847059,\n",
              " 0.8555801797231709,\n",
              " 0.763089467457603,\n",
              " 0.6555642718796352,\n",
              " 0.7314694317235555,\n",
              " 0.7635462593300749,\n",
              " 0.6056780466202266,\n",
              " 0.7129945513959671,\n",
              " 0.8535586597219676,\n",
              " 0.8025983696859882,\n",
              " 0.7792528924638515,\n",
              " 0.8314287378161548,\n",
              " 0.8069061853151611,\n",
              " 0.511758850443724,\n",
              " 0.506101443451841,\n",
              " 0.49829512500603174,\n",
              " 0.5792708992665646,\n",
              " 0.9052685786218684,\n",
              " 0.891399438228264,\n",
              " 0.8875538109084925,\n",
              " 0.8049685712625853,\n",
              " 0.7007663153923145,\n",
              " 0.6571131545318764,\n",
              " 0.4529616143188619,\n",
              " -0.09875940552655199,\n",
              " 0.7498077040004153,\n",
              " 0.6747388150057454,\n",
              " 0.6803900189805454,\n",
              " 0.6530254370270695,\n",
              " 0.718277470151166,\n",
              " 0.7949797905433527,\n",
              " 0.8406085336493672,\n",
              " 0.7736119754338728,\n",
              " 0.8663728240991727,\n",
              " 0.8367685808648911,\n",
              " 0.7858402680703279,\n",
              " 0.7821044712307003,\n",
              " 0.9542796666095303,\n",
              " 0.9505241901291936,\n",
              " 0.9435043350394526,\n",
              " 0.9517328478993187,\n",
              " 0.9606711405341826,\n",
              " 0.9480742974168098,\n",
              " 0.9100647607791177,\n",
              " 0.7619897890486798,\n",
              " 0.8673885821948182,\n",
              " 0.8780669573143425,\n",
              " 0.87477463795723,\n",
              " 0.8825226637819746,\n",
              " 0.7618385274812404,\n",
              " 0.8602923880458083,\n",
              " 0.926838080475838,\n",
              " 0.854073053843616,\n",
              " 0.8678281682319497,\n",
              " 0.7483209934569395,\n",
              " 0.7452673770643216,\n",
              " 0.7580656483994436,\n",
              " 0.5895110482743535,\n",
              " 0.49612694181091943,\n",
              " 0.7783894061035738,\n",
              " 0.8482147323957095,\n",
              " 0.8205642586770769,\n",
              " 0.9196892627701554,\n",
              " 0.9644189061498645,\n",
              " 0.8730013659992314,\n",
              " 0.8143574577377753,\n",
              " 0.26660069277215276,\n",
              " 0.6469022256051191,\n",
              " 0.7473086579824894,\n",
              " 0.42356496124325643,\n",
              " 0.9231502247898493,\n",
              " 0.897375337247859,\n",
              " 0.9545505719030959,\n",
              " 0.8720593981569074,\n",
              " 0.7064824859324835,\n",
              " 0.5586000425477445,\n",
              " 0.688135314570479,\n",
              " 0.8708113091748004,\n",
              " 0.8102987985211861,\n",
              " 0.8764395842995738,\n",
              " 0.8695169472167978,\n",
              " 0.7959520927791398,\n",
              " 0.8613083108646574,\n",
              " 0.8128181411349532,\n",
              " 0.6544753401942521,\n",
              " 0.649532475865017,\n",
              " 0.18467902766968605,\n",
              " 0.13317767804539973,\n",
              " 0.16002893155461342,\n",
              " 0.5854680504377987,\n",
              " 0.6742110244570789,\n",
              " 0.739931431917029,\n",
              " 0.8141866597007554,\n",
              " 0.8205783849980889,\n",
              " 0.6255122543470008,\n",
              " 0.3821416769100017,\n",
              " 0.8081309021652291,\n",
              " 0.9061919631842917,\n",
              " 0.8977370257496121,\n",
              " 0.7916383766819715,\n",
              " 0.8587322691278847,\n",
              " 0.8725263098678626,\n",
              " 0.7633629584536912,\n",
              " 0.8412978021919231,\n",
              " 0.74844624877633,\n",
              " 0.6593102577919157,\n",
              " 0.9326151481771792,\n",
              " 0.8059592308312166,\n",
              " 0.8347666173494577,\n",
              " 0.3420286209956707,\n",
              " 0.7467198570686847,\n",
              " 0.7797011306021882,\n",
              " 0.909978148287925,\n",
              " 0.9084478058893313,\n",
              " 0.9321563586478443,\n",
              " 0.892776873089693,\n",
              " 0.8868787190732289,\n",
              " 0.9324098574919734,\n",
              " 0.8492532116592454,\n",
              " 0.659510839051803,\n",
              " 0.8325623384089353,\n",
              " 0.8620470261389995,\n",
              " 0.8512432203341552,\n",
              " 0.6231485379055126,\n",
              " 0.640950418327768,\n",
              " 0.7037151075655771,\n",
              " 0.8709468884351601,\n",
              " 0.7646186577104386,\n",
              " 0.9569972385150336,\n",
              " 0.707297794808296,\n",
              " 0.8504412356071257,\n",
              " 0.8419125524945837,\n",
              " 0.7457041515325582,\n",
              " 0.9082328189071185,\n",
              " 0.8753446838495617,\n",
              " 0.8795493680738421,\n",
              " 0.8719894033714686,\n",
              " 0.9200974096229099,\n",
              " 0.8745736051181457,\n",
              " 0.9117580194137312,\n",
              " 0.8604498330877058,\n",
              " 0.5000558330439101,\n",
              " 0.6335419117455069,\n",
              " 0.7662934326656632,\n",
              " 0.8216284583465658,\n",
              " 0.7703951548373535,\n",
              " 0.8069234174997804,\n",
              " 0.7743024343662294,\n",
              " 0.8924579747276628,\n",
              " 0.9549484350843335,\n",
              " 0.9625998205258998,\n",
              " 0.9493861678941915,\n",
              " 0.9690398444613402,\n",
              " 0.9322829937812812,\n",
              " 0.9379225948338786,\n",
              " 0.8518748520765291,\n",
              " 0.887871311640967,\n",
              " 0.8455629933263034,\n",
              " 0.7511554800820059,\n",
              " 0.8897546486422512,\n",
              " 0.8487254676798704,\n",
              " 0.8048988579499201,\n",
              " 0.5478686507138493,\n",
              " 0.35995602207299526,\n",
              " 0.4221230340568992,\n",
              " 0.8915095752424751,\n",
              " 0.9347211423847165,\n",
              " 0.9191679905524285,\n",
              " 0.9551254540920082,\n",
              " 0.9403307103057049,\n",
              " 0.8509375185484783,\n",
              " 0.7157043346588028,\n",
              " 0.6367191463659425,\n",
              " 0.8567057775645618,\n",
              " 0.8899237819356118,\n",
              " 0.9272066358899855,\n",
              " 0.7007981868341102,\n",
              " 0.6888142545710674,\n",
              " 0.8311982737704519,\n",
              " 0.785492107398239,\n",
              " 0.9423125837034305,\n",
              " 0.8918795407497665,\n",
              " 0.7796782435129221,\n",
              " 0.832350233114359,\n",
              " 0.8323511135110664,\n",
              " 0.8492806378675536,\n",
              " 0.5980756924448897,\n",
              " 0.92088249724305,\n",
              " 0.6121889997888136,\n",
              " 0.8179177671659892,\n",
              " 0.8250496972114131,\n",
              " 0.661702815589412,\n",
              " 0.6796707037190245,\n",
              " 0.5365364533706799,\n",
              " 0.890027877984279,\n",
              " 0.9257444677223525,\n",
              " 0.8525066139048133,\n",
              " 0.8480407089199241,\n",
              " 0.8882413863563201,\n",
              " 0.8009423998868913,\n",
              " 0.8541877169275346,\n",
              " 0.9052228550402751,\n",
              " 0.7889720758770756,\n",
              " 0.7917902983634139,\n",
              " 0.7702892822523113,\n",
              " 0.8789363928738165,\n",
              " 0.8237491016129403,\n",
              " 0.7470008890177378,\n",
              " 0.7592584830577266,\n",
              " 0.852577833732447,\n",
              " 0.7501572373868166,\n",
              " 0.6864959050251781,\n",
              " 0.7551883089860845,\n",
              " 0.8004034287360242,\n",
              " 0.7895617429850598,\n",
              " 0.8701480372050429,\n",
              " 0.7045359283451245,\n",
              " 0.567819263180194,\n",
              " 0.7866889299813302,\n",
              " 0.8813901766077279,\n",
              " 0.740374163589016,\n",
              " 0.8475793113205318,\n",
              " 0.7331693944245489,\n",
              " 0.6557056730294988,\n",
              " 0.5374826781532546,\n",
              " 0.7242274845065967,\n",
              " 0.8776559007627351,\n",
              " 0.8893282753841603,\n",
              " 0.9527123264861524,\n",
              " 0.8443529656766309,\n",
              " 0.845575071507363,\n",
              " 0.6155735230435616,\n",
              " 0.570704402617837,\n",
              " 0.6736266165308952,\n",
              " 0.7581621389829778,\n",
              " 0.8733362910605433,\n",
              " 0.9204045493226001,\n",
              " 0.8223903890819269,\n",
              " 0.4931488485907715,\n",
              " 0.5414340332697923,\n",
              " 0.8120881168559656,\n",
              " 0.753746101177125,\n",
              " 0.8361900233772377,\n",
              " 0.8059864132891675,\n",
              " 0.8377711444797625,\n",
              " 0.781289523494635,\n",
              " 0.8602873171100165,\n",
              " 0.9308684344808603,\n",
              " 0.7955968533047811,\n",
              " 0.9101471034230496,\n",
              " 0.843755834077816,\n",
              " 0.8919333245164521,\n",
              " 0.9339523848397436,\n",
              " 0.9384872905423743,\n",
              " 0.9052873340221651,\n",
              " 0.9378421777661156,\n",
              " 0.8969175673625801,\n",
              " 0.6356253620668619,\n",
              " 0.8776078625251816,\n",
              " 0.9011407329589219,\n",
              " 0.8320719500419356,\n",
              " 0.712548564900017,\n",
              " 0.827865770033408,\n",
              " 0.6360849783332557,\n",
              " 0.6533175396670509,\n",
              " 0.9123071401209913,\n",
              " 0.9377627384594145,\n",
              " 0.9144939627077566,\n",
              " 0.8865994729421042,\n",
              " 0.8556005836777598,\n",
              " 0.8962891742917803,\n",
              " 0.4865794982541676,\n",
              " 0.8236940970737334,\n",
              " 0.5763321446980775,\n",
              " 0.9306243994220069,\n",
              " 0.8112649305300912,\n",
              " 0.9617472288185279,\n",
              " 0.9618830523611291,\n",
              " 0.9474015373837082,\n",
              " 0.8719269014816576,\n",
              " 0.710354063216113,\n",
              " 0.6953116347464107,\n",
              " 0.8231854341828077,\n",
              " 0.8256806263484299,\n",
              " 0.8502009599900057,\n",
              " 0.9292358824644891,\n",
              " 0.9257654357856456,\n",
              " 0.8950038784554505,\n",
              " 0.8675261138003354,\n",
              " 0.8726432183298694,\n",
              " 0.6632695783228963,\n",
              " 0.7801000411980041,\n",
              " 0.4878503303614249,\n",
              " 0.7790564501599001,\n",
              " 0.863739672443515,\n",
              " 0.9063590861955516,\n",
              " 0.8959828437061019,\n",
              " 0.9516190889908892,\n",
              " 0.7184969361843552,\n",
              " 0.8683566731076539,\n",
              " 0.6519844768268129,\n",
              " 0.8491368863422045,\n",
              " 0.9187243364020663,\n",
              " 0.8811758145395775,\n",
              " 0.882701352449671,\n",
              " 0.938107138912561,\n",
              " 0.7453842972615693,\n",
              " 0.8973404010847358,\n",
              " 0.8521881958354562,\n",
              " 0.9240593172956204,\n",
              " 0.8791734108269987,\n",
              " 0.8493660436134296,\n",
              " 0.8958657768950101,\n",
              " 0.7211563999490196,\n",
              " 0.8740240051672938,\n",
              " 0.8921387768968578,\n",
              " 0.8825092096184803,\n",
              " 0.8609134944819987,\n",
              " 0.940739495981494,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg-UwTfwBYDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_csv():\n",
        "  frame = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uesq5EAX2ESF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Graphical Display to plot weights\n",
        "def plot_weights(weights, electi):\n",
        " \n",
        "        \n",
        "    T = np.arange(0, 0.00625*stim, 0.00625)                       # creation of the time variable (on 1s) for the abscissa\n",
        "    \n",
        "    nbr_elct = len(electi)\n",
        "    (Lo_W, la_W) = weights[0].shape\n",
        "    Lo_W = int(Lo_W)                                              # number of lines: inputs (160 * nbr_electrodes, for example)\n",
        "    la_W = int(la_W)                                              # number of columns: number of neurons in the layer\n",
        "    \n",
        "    z=0\n",
        "    while z < nbr_elct:                                           # for each electrode\n",
        "        z_1=0 \n",
        "        while z_1 < la_W:                                         # for each neuron of the W layer [1]\n",
        "            W_tmp = tf.slice(K.constant(weights[0]), [0, z_1], [Lo_W, 1])           # slice: starting value [line 0, column of the neuron], dimensions of the section [160 * nbr_electrodes lines, 1 column])\n",
        "            W_tmp = tf.slice(W_tmp, [z*stim, 0], [stim, 1])       # slice: starting value [first value of the new electrode, column 0], dimensions of the section [160 lines, 1 column]\n",
        "            print (W_tmp.shape)\n",
        "            \n",
        "            plt.plot(T, K.eval(W_tmp), label= (\"neurone_\", z_1, \"layer_1, electrode_\", electi[z]))\n",
        "            z_1 = z_1+1\n",
        "            \n",
        "        z = z+1\n",
        "        \n",
        "    plt.legend()    \n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q354AwSR2ESG",
        "colab_type": "code",
        "outputId": "5562dff6-fa66-4297-be99-c7cd3b5eb317",
        "colab": {}
      },
      "source": [
        "weights = np.array(model.get_weights()) #Convert the weights into np array\n",
        "\n",
        "plot_weights(weights, electi)            #Plot the weights of the model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PbK-ywf2ESI",
        "colab_type": "code",
        "outputId": "90e8c1fb-5c97-488f-8e17-1ac32fe3a611",
        "colab": {}
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}