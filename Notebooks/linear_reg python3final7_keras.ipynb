{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "rng = np.random\n",
    "from array import array\n",
    "from scipy import stats\n",
    "\n",
    "#Keras import \n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "\n",
    "#import models\n",
    "from Linear_Regression import linear_regression\n",
    "\n",
    "#import datetime for tensorboard\n",
    "from datetime import *\n",
    "\n",
    "#Import for reading the MATLAB files\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load EEG data of all subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg_data():\n",
    "    '''\n",
    "    Function to load EEG data of all subjects \n",
    "    '''\n",
    "    eeg_data = []\n",
    "    for name in glob.glob('*.mat'):\n",
    "        # data import from matlab\n",
    "        subject = sio.loadmat(name)   #Load the matlab file for a single subject \n",
    "        data_subject = subject['data']\n",
    "\n",
    "\n",
    "        # shuffle trials\n",
    "        (channel, trial, time_points)= data_subject.shape\n",
    "\n",
    "        trials = np.arange(trial)\n",
    "        np.random.shuffle(trials)\n",
    "\n",
    "        #Z score\n",
    "        data_subject=stats.zscore(format_1, axis=2)\n",
    "        \n",
    "        eeg_data.append(data_subject)\n",
    "    return np.array(eeg_data)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 192, 1000)\n",
      "(65, 192, 1000)\n"
     ]
    }
   ],
   "source": [
    "#Load data for only a single subject as of now for the purpose of prototyping \n",
    "\n",
    "\n",
    "# data import from matlab\n",
    "subject_1 = sio.loadmat('1.mat')      #recovering matlab data in the form of a python dictionar\n",
    "format_1 = subject_1['data']          #in the dictionary, only the data key interests us\n",
    "print (format_1.shape)\n",
    "\n",
    "# shuffle trials\n",
    "(channel, trial, time_points)= format_1.shape\n",
    "\n",
    "trials = np.arange(trial)\n",
    "np.random.shuffle(trials)\n",
    "\n",
    "#Z score\n",
    "format_1=stats.zscore(format_1, axis=2)\n",
    "\n",
    "\n",
    "# data import from matlab\n",
    "subject_1 = sio.loadmat('1.mat')      #recovering matlab data in the form of a python dictionar\n",
    "format_1 = subject_1['data']          #in the dictionary, only the data key interests us\n",
    "print (format_1.shape)\n",
    "\n",
    "# shuffle trials\n",
    "(channel, trial, time_points)= format_1.shape\n",
    "\n",
    "trials = np.arange(trial)\n",
    "np.random.shuffle(trials)\n",
    "\n",
    "#Z score\n",
    "format_1=stats.zscore(format_1, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 65, 192, 1000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_eeg_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(format_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the electrode number:30\n",
      "<class 'list'>\n",
      "[30]\n",
      "Enter the number of stimuli:160\n",
      "Please define what should be predicted (1 for EEG or 2 for stimulus):1\n",
      "please specify the number of layers and neurons per desired layers: 1\n",
      "[1]\n",
      "<class 'list'>\n",
      "enter the lambda / learning rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "# parametres\n",
    "\n",
    "eltmp = input ('''Enter the electrode number:''')\n",
    "electi = list(map(int, eltmp.split()))    #separation of the different responses and recovery in the form of a list of integers\n",
    "print (type(electi))\n",
    "print(electi)\n",
    "\n",
    "stim = input ('''Enter the number of stimuli:''')\n",
    "stim = int(stim)\n",
    "\n",
    "relation = input('''Please define what should be predicted (1 for EEG or 2 for stimulus):''')\n",
    "\n",
    "if relation == '1':\n",
    "    source_Y = electi[0]    #retrieving the electrode number as a whole number - implies that there is only one electrode chosen in this direction\n",
    "    source_X = [0]          #conversion of the stimuli line in the form of a list - necessary for the for loop: see below - extraction X\n",
    "\n",
    "elif relation == '2':\n",
    "    format_1 = np.flip(format_1,2)     # data inversion according to the time dimension - problem ????\n",
    "    source_Y = 0\n",
    "    source_X = electi\n",
    "\n",
    "hiLaSi_tmp = input('''please specify the number of layers and neurons per desired layers: ''')\n",
    "hidden_layers_size = list(map(int, hiLaSi_tmp.split()))\n",
    "print (hidden_layers_size)\n",
    "print (type(hidden_layers_size))\n",
    "\n",
    "learning_rate = input('''enter the lambda / learning rate: ''')\n",
    "learning_rate = float(learning_rate)      # conversion as a decimal number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### separation of train tests / valid / test\n",
    "def split_data()\n",
    "train_num = int(np.around(len(trials) * 0.8))\n",
    "valid_num = int(np.around(len(trials) * 0.1))\n",
    "test_num = len(trials) - train_num - valid_num\n",
    "\n",
    "trials_train = trials[0:train_num]\n",
    "trials_valid = trials[train_num:train_num+valid_num]\n",
    "trials_test = trials[train_num+valid_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape =  (129360, 1)\n",
      "y_valid.shape =  (15960, 1)\n",
      "y_test.shape =  (15960, 1)\n"
     ]
    }
   ],
   "source": [
    "# extract data from format_1\n",
    "\n",
    "def extract_Y (batch_trials, batch_num):              #creation of a function to recover y - simplification of reading\n",
    "    \n",
    "    y_tmp=format_1[source_Y, batch_trials, stim:]     #recovery of Y in the form of a matrix of 154 * 840\n",
    "    y_tmp=np.reshape(y_tmp, ((time_points-stim)*batch_num))    #passage through the list of 129 360 values ​​(test 0, test 1, ... test 153)\n",
    "    y_tmp=np.matrix(y_tmp)                           #1 * 129360 matrix conversion\n",
    "    y_tmp=np.transpose(y_tmp)                        #transposition into a matrix of 129360 * 1, matrix equal to that of Matlab (necessary for the rest)\n",
    "    return y_tmp                                     #returns the content of y_tmp\n",
    "    \n",
    "y_train = extract_Y (trials_train, train_num)\n",
    "print (\"y_train.shape = \", y_train.shape)\n",
    "y_valid = extract_Y (trials_valid, valid_num)\n",
    "print (\"y_valid.shape = \", y_valid.shape)\n",
    "y_test = extract_Y (trials_test, test_num)\n",
    "print (\"y_test.shape = \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  (129360, 160)\n",
      "x_valid.shape =  (15960, 160)\n",
      "x_test.shape =  (15960, 160)\n"
     ]
    }
   ],
   "source": [
    "def extract_X (batch_trials, batch_num):                     #creation of a function to recover x - simplification of reading\n",
    "    x_tmp = [[]]*((time_points-stim)*batch_num)                       #creation of an empty list x_tmp of size (129630,)\n",
    "    x_tmp = np.matrix(x_tmp)                                #conversion as a matrix 129630 * 0 (number of lines good)\n",
    "    x_tmp = np.transpose(x_tmp)                             #transposition 1: form 0 * 129630, necessary at n.append\n",
    "                                                            #avoid the transposition line in the for loop (2 transpo instead of 160\n",
    "    for i in source_X:                                      #reading the source list -> reading each electrode number if flip\n",
    "        k = 0\n",
    "        while k < stim:                                     #160 loops - recovery of the 840 values ​​of each test (in the form test 1, test 2, ...), shifted by 1 at each iteration\n",
    "            tmp = format_1[i, batch_trials, k:(time_points-stim+k)]    #see extract_Y\n",
    "            tmp = np.reshape(tmp,((time_points-stim)*batch_num))\n",
    "            tmp = np.matrix(tmp)\n",
    "            \n",
    "            x_tmp = np.append(x_tmp, tmp, axis=0)           #concatenation of the matrix tmp 1 * 129360 at the end of the matrix x_tmp (k + 1) * 129360\n",
    "            k = k+1\n",
    "    x_tmp = np.transpose(x_tmp)                             #transposition 2: form 129360 * (160 * nbr_électrode)\n",
    "    return x_tmp\n",
    "        \n",
    "x_train = extract_X (trials_train, train_num)\n",
    "print (\"x_train.shape = \", x_train.shape)\n",
    "x_valid = extract_X (trials_valid, valid_num)\n",
    "print (\"x_valid.shape = \", x_valid.shape)\n",
    "x_test = extract_X (trials_test, test_num)\n",
    "print (\"x_test.shape = \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129360, 160)\n",
      "(129360, 1)\n"
     ]
    }
   ],
   "source": [
    "#tensorflow - Linear regression cf github\n",
    "\n",
    "training_epochs = 200\n",
    "display_step = 10\n",
    "\n",
    "train_X = x_train\n",
    "print(train_X.shape)\n",
    "train_Y = y_train\n",
    "print(train_Y.shape)\n",
    "n_samples_train = train_X.shape[0]\n",
    "\n",
    "valid_X = x_valid\n",
    "valid_Y = y_valid\n",
    "n_samples_valid = valid_X.shape[0]\n",
    "\n",
    "test_X = x_test\n",
    "test_Y = y_test\n",
    "n_samples_test = test_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Keras Model \n",
    "model = linear_regression(train_X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/scalars/20200115-163712\n"
     ]
    }
   ],
   "source": [
    "#Set Up Tensorboard for visualisation for training\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training Loss \n",
    "def mse(y_true, y_pred):\n",
    "    return (K.mean(K.square(y_pred - y_true), axis=-1)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the Optimizers\n",
    "sgd = optimizers.SGD(lr = learning_rate)\n",
    "adam = optimizers.Adam(lr = learning_rate)\n",
    "rmsprop = optimizers.RMSprop(lr = learning_rate)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss = mse, optimizer = sgd , metrics=[mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 129360 samples, validate on 15960 samples\n",
      "Epoch 1/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6410 - mse: 0.6410 - val_loss: 0.6323 - val_mse: 0.6323\n",
      "Epoch 2/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.6922 - val_mse: 0.6922\n",
      "Epoch 3/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6430 - mse: 0.6430 - val_loss: 0.6526 - val_mse: 0.6526\n",
      "Epoch 4/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6441 - mse: 0.6441 - val_loss: 0.6366 - val_mse: 0.6366\n",
      "Epoch 5/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6423 - mse: 0.6423 - val_loss: 0.6429 - val_mse: 0.6429\n",
      "Epoch 6/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6414 - mse: 0.6414 - val_loss: 0.6559 - val_mse: 0.6559\n",
      "Epoch 7/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.6579 - val_mse: 0.6579\n",
      "Epoch 8/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6401 - mse: 0.6401 - val_loss: 0.6743 - val_mse: 0.6743\n",
      "Epoch 9/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6416 - mse: 0.6416 - val_loss: 0.6974 - val_mse: 0.6974\n",
      "Epoch 10/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6415 - mse: 0.6415 - val_loss: 0.6250 - val_mse: 0.6250\n",
      "Epoch 11/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6417 - mse: 0.6417 - val_loss: 0.6480 - val_mse: 0.6480\n",
      "Epoch 12/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6433 - mse: 0.6433 - val_loss: 0.6324 - val_mse: 0.6324\n",
      "Epoch 13/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.6256 - val_mse: 0.6256\n",
      "Epoch 14/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6435 - mse: 0.6435 - val_loss: 0.7104 - val_mse: 0.7104\n",
      "Epoch 15/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 0.6395 - val_mse: 0.6395\n",
      "Epoch 16/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.6715 - val_mse: 0.6715\n",
      "Epoch 17/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.6955 - val_mse: 0.6955\n",
      "Epoch 18/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6432 - mse: 0.6432 - val_loss: 0.6565 - val_mse: 0.6565\n",
      "Epoch 19/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6407 - mse: 0.6407 - val_loss: 0.6613 - val_mse: 0.6613\n",
      "Epoch 20/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6400 - mse: 0.6400 - val_loss: 0.6686 - val_mse: 0.6686\n",
      "Epoch 21/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6429 - mse: 0.6429 - val_loss: 0.6535 - val_mse: 0.6535\n",
      "Epoch 22/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.6360 - val_mse: 0.6360\n",
      "Epoch 23/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6420 - mse: 0.6420 - val_loss: 0.6696 - val_mse: 0.6696\n",
      "Epoch 24/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.6856 - val_mse: 0.6856\n",
      "Epoch 25/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6432 - mse: 0.6432 - val_loss: 0.7013 - val_mse: 0.7013\n",
      "Epoch 26/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6410 - mse: 0.6410 - val_loss: 0.6791 - val_mse: 0.6791\n",
      "Epoch 27/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.6506 - val_mse: 0.6506\n",
      "Epoch 28/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.6597 - val_mse: 0.6597\n",
      "Epoch 29/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6424 - mse: 0.6424 - val_loss: 0.6742 - val_mse: 0.6742\n",
      "Epoch 30/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6400 - mse: 0.6400 - val_loss: 0.6135 - val_mse: 0.6135\n",
      "Epoch 31/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6427 - mse: 0.6426 - val_loss: 0.6781 - val_mse: 0.6781\n",
      "Epoch 32/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6433 - mse: 0.6433 - val_loss: 0.6329 - val_mse: 0.6329\n",
      "Epoch 33/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6413 - mse: 0.6413 - val_loss: 0.6011 - val_mse: 0.6011\n",
      "Epoch 34/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.6500 - val_mse: 0.6500\n",
      "Epoch 35/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6408 - mse: 0.6408 - val_loss: 0.6978 - val_mse: 0.6978\n",
      "Epoch 36/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6423 - mse: 0.6423 - val_loss: 0.6468 - val_mse: 0.6468\n",
      "Epoch 37/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6437 - mse: 0.6437 - val_loss: 0.6759 - val_mse: 0.6759\n",
      "Epoch 38/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.6169 - val_mse: 0.6169\n",
      "Epoch 39/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.6318 - val_mse: 0.6318\n",
      "Epoch 40/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 0.6446 - val_mse: 0.6446\n",
      "Epoch 41/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.6790 - val_mse: 0.6790\n",
      "Epoch 42/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6436 - mse: 0.6436 - val_loss: 0.6328 - val_mse: 0.6328\n",
      "Epoch 43/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6445 - mse: 0.6445 - val_loss: 0.6339 - val_mse: 0.6339\n",
      "Epoch 44/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 0.6860 - val_mse: 0.6860\n",
      "Epoch 45/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.6414 - val_mse: 0.6414\n",
      "Epoch 46/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6428 - mse: 0.6428 - val_loss: 0.6702 - val_mse: 0.6702\n",
      "Epoch 47/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.6356 - val_mse: 0.6356\n",
      "Epoch 48/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6401 - mse: 0.6401 - val_loss: 0.6593 - val_mse: 0.6593\n",
      "Epoch 49/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6435 - mse: 0.6435 - val_loss: 0.6658 - val_mse: 0.6658\n",
      "Epoch 50/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 0.6227 - val_mse: 0.6227\n",
      "Epoch 51/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 0.6293 - val_mse: 0.6293\n",
      "Epoch 52/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6429 - mse: 0.6429 - val_loss: 0.5983 - val_mse: 0.5983\n",
      "Epoch 53/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6428 - mse: 0.6428 - val_loss: 0.6516 - val_mse: 0.6516\n",
      "Epoch 54/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6430 - mse: 0.6430 - val_loss: 0.6682 - val_mse: 0.6682\n",
      "Epoch 55/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6417 - mse: 0.6417 - val_loss: 0.6436 - val_mse: 0.6436\n",
      "Epoch 56/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6429 - mse: 0.6429 - val_loss: 0.6286 - val_mse: 0.6286\n",
      "Epoch 57/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6413 - mse: 0.6413 - val_loss: 0.6517 - val_mse: 0.6517\n",
      "Epoch 58/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.6644 - val_mse: 0.6644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6433 - mse: 0.6433 - val_loss: 0.6175 - val_mse: 0.6175\n",
      "Epoch 60/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6433 - mse: 0.6433 - val_loss: 0.6779 - val_mse: 0.6779\n",
      "Epoch 61/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6448 - mse: 0.6448 - val_loss: 0.6624 - val_mse: 0.6624\n",
      "Epoch 62/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.7177 - val_mse: 0.7177\n",
      "Epoch 63/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.6852 - val_mse: 0.6852\n",
      "Epoch 64/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6407 - mse: 0.6407 - val_loss: 0.6920 - val_mse: 0.6920\n",
      "Epoch 65/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.6417 - val_mse: 0.6417\n",
      "Epoch 66/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.6349 - val_mse: 0.6349\n",
      "Epoch 67/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6415 - mse: 0.6415 - val_loss: 0.6139 - val_mse: 0.6139\n",
      "Epoch 68/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6393 - mse: 0.6393 - val_loss: 0.6519 - val_mse: 0.6519\n",
      "Epoch 69/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6424 - mse: 0.6424 - val_loss: 0.6436 - val_mse: 0.6436\n",
      "Epoch 70/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.6963 - val_mse: 0.6963\n",
      "Epoch 71/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6436 - mse: 0.6436 - val_loss: 0.6989 - val_mse: 0.6989\n",
      "Epoch 72/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6440 - mse: 0.6440 - val_loss: 0.6272 - val_mse: 0.6272\n",
      "Epoch 73/200\n",
      "129360/129360 [==============================] - 7s 56us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.6222 - val_mse: 0.6222\n",
      "Epoch 74/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6424 - mse: 0.6424 - val_loss: 0.6097 - val_mse: 0.6097\n",
      "Epoch 75/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6404 - mse: 0.6404 - val_loss: 0.6222 - val_mse: 0.6222\n",
      "Epoch 76/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6424 - mse: 0.6424 - val_loss: 0.6346 - val_mse: 0.6346\n",
      "Epoch 77/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6429 - mse: 0.6429 - val_loss: 0.7235 - val_mse: 0.7235\n",
      "Epoch 78/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6445 - mse: 0.6445 - val_loss: 0.6291 - val_mse: 0.6291\n",
      "Epoch 79/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6391 - mse: 0.6391 - val_loss: 0.6282 - val_mse: 0.6282\n",
      "Epoch 80/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.6734 - val_mse: 0.6734\n",
      "Epoch 81/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.6362 - val_mse: 0.6362\n",
      "Epoch 82/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6435 - mse: 0.6435 - val_loss: 0.6532 - val_mse: 0.6532\n",
      "Epoch 83/200\n",
      "129360/129360 [==============================] - 7s 51us/step - loss: 0.6409 - mse: 0.6409 - val_loss: 0.6571 - val_mse: 0.6571\n",
      "Epoch 84/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6414 - mse: 0.6414 - val_loss: 0.6154 - val_mse: 0.6154\n",
      "Epoch 85/200\n",
      "129360/129360 [==============================] - 7s 50us/step - loss: 0.6433 - mse: 0.6433 - val_loss: 0.6346 - val_mse: 0.6346\n",
      "Epoch 86/200\n",
      "129360/129360 [==============================] - 6s 47us/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.6535 - val_mse: 0.6535\n",
      "Epoch 87/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 0.6850 - val_mse: 0.6850\n",
      "Epoch 88/200\n",
      "129360/129360 [==============================] - 6s 49us/step - loss: 0.6416 - mse: 0.6416 - val_loss: 0.7066 - val_mse: 0.7066\n",
      "Epoch 89/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.6402 - val_mse: 0.6402\n",
      "Epoch 90/200\n",
      "129360/129360 [==============================] - 7s 51us/step - loss: 0.6430 - mse: 0.6430 - val_loss: 0.6408 - val_mse: 0.6408\n",
      "Epoch 91/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6436 - mse: 0.6436 - val_loss: 0.6274 - val_mse: 0.6274\n",
      "Epoch 92/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6413 - mse: 0.6413 - val_loss: 0.6199 - val_mse: 0.6199\n",
      "Epoch 93/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6410 - mse: 0.6410 - val_loss: 0.6816 - val_mse: 0.6816\n",
      "Epoch 94/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.6494 - val_mse: 0.6494\n",
      "Epoch 95/200\n",
      "129360/129360 [==============================] - 6s 48us/step - loss: 0.6414 - mse: 0.6414 - val_loss: 0.6266 - val_mse: 0.6266\n",
      "Epoch 96/200\n",
      "129360/129360 [==============================] - 6s 49us/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.6204 - val_mse: 0.6204\n",
      "Epoch 97/200\n",
      "129360/129360 [==============================] - 6s 49us/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.6807 - val_mse: 0.6807\n",
      "Epoch 98/200\n",
      "129360/129360 [==============================] - 6s 50us/step - loss: 0.6424 - mse: 0.6424 - val_loss: 0.6785 - val_mse: 0.6785\n",
      "Epoch 99/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6408 - mse: 0.6408 - val_loss: 0.6448 - val_mse: 0.6448\n",
      "Epoch 100/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.6271 - val_mse: 0.6271\n",
      "Epoch 101/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.6483 - val_mse: 0.6483\n",
      "Epoch 102/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.6493 - val_mse: 0.6493\n",
      "Epoch 103/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6414 - mse: 0.6414 - val_loss: 0.6384 - val_mse: 0.6384\n",
      "Epoch 104/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6423 - mse: 0.6423 - val_loss: 0.6729 - val_mse: 0.6729\n",
      "Epoch 105/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6449 - mse: 0.6449 - val_loss: 0.6553 - val_mse: 0.6553\n",
      "Epoch 106/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.6499 - val_mse: 0.6499\n",
      "Epoch 107/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.6405 - val_mse: 0.6405\n",
      "Epoch 108/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.6501 - val_mse: 0.6501\n",
      "Epoch 109/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6410 - mse: 0.6410 - val_loss: 0.6175 - val_mse: 0.6175\n",
      "Epoch 110/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6423 - mse: 0.6423 - val_loss: 0.6447 - val_mse: 0.6447\n",
      "Epoch 111/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 0.6331 - val_mse: 0.6331\n",
      "Epoch 112/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.6809 - val_mse: 0.6809\n",
      "Epoch 113/200\n",
      "129360/129360 [==============================] - 7s 51us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 0.6385 - val_mse: 0.6385\n",
      "Epoch 114/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.6629 - val_mse: 0.6629\n",
      "Epoch 115/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6418 - mse: 0.6418 - val_loss: 0.6172 - val_mse: 0.6172\n",
      "Epoch 116/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.6706 - val_mse: 0.6706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6437 - mse: 0.6437 - val_loss: 0.6318 - val_mse: 0.6318\n",
      "Epoch 118/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 0.6523 - val_mse: 0.6523\n",
      "Epoch 119/200\n",
      "129360/129360 [==============================] - 7s 56us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.6757 - val_mse: 0.6757\n",
      "Epoch 120/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6420 - mse: 0.6420 - val_loss: 0.6240 - val_mse: 0.6240\n",
      "Epoch 121/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.6517 - val_mse: 0.6517\n",
      "Epoch 122/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.6169 - val_mse: 0.6169\n",
      "Epoch 123/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.6700 - val_mse: 0.6700\n",
      "Epoch 124/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6415 - mse: 0.6415 - val_loss: 0.6243 - val_mse: 0.6243\n",
      "Epoch 125/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.6466 - val_mse: 0.6466\n",
      "Epoch 126/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 0.6630 - val_mse: 0.6630\n",
      "Epoch 127/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6410 - mse: 0.6410 - val_loss: 0.6316 - val_mse: 0.6316\n",
      "Epoch 128/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6430 - mse: 0.6430 - val_loss: 0.6706 - val_mse: 0.6706\n",
      "Epoch 129/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6430 - mse: 0.6430 - val_loss: 0.6432 - val_mse: 0.6432\n",
      "Epoch 130/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6408 - mse: 0.6408 - val_loss: 0.6548 - val_mse: 0.6548\n",
      "Epoch 131/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6449 - mse: 0.6449 - val_loss: 0.6569 - val_mse: 0.6569\n",
      "Epoch 132/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6416 - mse: 0.6416 - val_loss: 0.6158 - val_mse: 0.6158\n",
      "Epoch 133/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6435 - mse: 0.6435 - val_loss: 0.6208 - val_mse: 0.6208\n",
      "Epoch 134/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6423 - mse: 0.6423 - val_loss: 0.7039 - val_mse: 0.7039\n",
      "Epoch 135/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6413 - mse: 0.6413 - val_loss: 0.6058 - val_mse: 0.6058\n",
      "Epoch 136/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6441 - mse: 0.6441 - val_loss: 0.6722 - val_mse: 0.6722\n",
      "Epoch 137/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.6563 - val_mse: 0.6563\n",
      "Epoch 138/200\n",
      "129360/129360 [==============================] - 7s 51us/step - loss: 0.6428 - mse: 0.6428 - val_loss: 0.6252 - val_mse: 0.6252\n",
      "Epoch 139/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6414 - mse: 0.6414 - val_loss: 0.6309 - val_mse: 0.6309\n",
      "Epoch 140/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.6283 - val_mse: 0.6283\n",
      "Epoch 141/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.6579 - val_mse: 0.6579\n",
      "Epoch 142/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6417 - mse: 0.6417 - val_loss: 0.6190 - val_mse: 0.6190\n",
      "Epoch 143/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6418 - mse: 0.6418 - val_loss: 0.6230 - val_mse: 0.6230\n",
      "Epoch 144/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6435 - mse: 0.6435 - val_loss: 0.6315 - val_mse: 0.6315\n",
      "Epoch 145/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6410 - mse: 0.6410 - val_loss: 0.6519 - val_mse: 0.6519\n",
      "Epoch 146/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6417 - mse: 0.6417 - val_loss: 0.6735 - val_mse: 0.6735\n",
      "Epoch 147/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6417 - mse: 0.6417 - val_loss: 0.6016 - val_mse: 0.6016\n",
      "Epoch 148/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6420 - mse: 0.6420 - val_loss: 0.6482 - val_mse: 0.6482\n",
      "Epoch 149/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.6201 - val_mse: 0.6201\n",
      "Epoch 150/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6415 - mse: 0.6415 - val_loss: 0.6381 - val_mse: 0.6381\n",
      "Epoch 151/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6420 - mse: 0.6420 - val_loss: 0.6708 - val_mse: 0.6708\n",
      "Epoch 152/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6440 - mse: 0.6440 - val_loss: 0.6206 - val_mse: 0.6206\n",
      "Epoch 153/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6401 - mse: 0.6401 - val_loss: 0.6511 - val_mse: 0.6511\n",
      "Epoch 154/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6424 - mse: 0.6424 - val_loss: 0.6313 - val_mse: 0.6313\n",
      "Epoch 155/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6403 - mse: 0.6403 - val_loss: 0.6654 - val_mse: 0.6654\n",
      "Epoch 156/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6418 - mse: 0.6418 - val_loss: 0.6121 - val_mse: 0.6121\n",
      "Epoch 157/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.6116 - val_mse: 0.6116\n",
      "Epoch 158/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6415 - mse: 0.6415 - val_loss: 0.6280 - val_mse: 0.6280\n",
      "Epoch 159/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.6445 - val_mse: 0.6445\n",
      "Epoch 160/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.7341 - val_mse: 0.7341\n",
      "Epoch 161/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6439 - mse: 0.6439 - val_loss: 0.6846 - val_mse: 0.6846\n",
      "Epoch 162/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.6230 - val_mse: 0.6230\n",
      "Epoch 163/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.6376 - val_mse: 0.6376\n",
      "Epoch 164/200\n",
      "129360/129360 [==============================] - 7s 51us/step - loss: 0.6396 - mse: 0.6396 - val_loss: 0.6379 - val_mse: 0.6379\n",
      "Epoch 165/200\n",
      "129360/129360 [==============================] - 6s 48us/step - loss: 0.6428 - mse: 0.6428 - val_loss: 0.6613 - val_mse: 0.6613\n",
      "Epoch 166/200\n",
      "129360/129360 [==============================] - 6s 49us/step - loss: 0.6407 - mse: 0.6407 - val_loss: 0.6420 - val_mse: 0.6420\n",
      "Epoch 167/200\n",
      "129360/129360 [==============================] - 6s 49us/step - loss: 0.6428 - mse: 0.6428 - val_loss: 0.6757 - val_mse: 0.6757\n",
      "Epoch 168/200\n",
      "129360/129360 [==============================] - 6s 50us/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.6410 - val_mse: 0.6410\n",
      "Epoch 169/200\n",
      "129360/129360 [==============================] - 7s 51us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.6368 - val_mse: 0.6368\n",
      "Epoch 170/200\n",
      "129360/129360 [==============================] - 7s 52us/step - loss: 0.6423 - mse: 0.6423 - val_loss: 0.6510 - val_mse: 0.6510\n",
      "Epoch 171/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.6526 - val_mse: 0.6526\n",
      "Epoch 172/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6413 - mse: 0.6413 - val_loss: 0.6513 - val_mse: 0.6513\n",
      "Epoch 173/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6436 - mse: 0.6436 - val_loss: 0.6327 - val_mse: 0.6327\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.7056 - val_mse: 0.7056\n",
      "Epoch 175/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 0.6895 - val_mse: 0.6895\n",
      "Epoch 176/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6396 - mse: 0.6396 - val_loss: 0.6631 - val_mse: 0.6631\n",
      "Epoch 177/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6419 - mse: 0.6419 - val_loss: 0.7048 - val_mse: 0.7048\n",
      "Epoch 178/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6420 - mse: 0.6420 - val_loss: 0.6140 - val_mse: 0.6140\n",
      "Epoch 179/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6399 - mse: 0.6399 - val_loss: 0.6529 - val_mse: 0.6529\n",
      "Epoch 180/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6420 - mse: 0.6420 - val_loss: 0.6354 - val_mse: 0.6354\n",
      "Epoch 181/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6418 - mse: 0.6418 - val_loss: 0.6592 - val_mse: 0.6592\n",
      "Epoch 182/200\n",
      "129360/129360 [==============================] - 7s 55us/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.6542 - val_mse: 0.6542\n",
      "Epoch 183/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.6490 - val_mse: 0.6490\n",
      "Epoch 184/200\n",
      "129360/129360 [==============================] - 7s 51us/step - loss: 0.6406 - mse: 0.6406 - val_loss: 0.6985 - val_mse: 0.6985\n",
      "Epoch 185/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6424 - mse: 0.6424 - val_loss: 0.6978 - val_mse: 0.6978\n",
      "Epoch 186/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6414 - mse: 0.6414 - val_loss: 0.6409 - val_mse: 0.6409\n",
      "Epoch 187/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.5818 - val_mse: 0.5818\n",
      "Epoch 188/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6429 - mse: 0.6429 - val_loss: 0.6260 - val_mse: 0.6260\n",
      "Epoch 189/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6409 - mse: 0.6409 - val_loss: 0.6308 - val_mse: 0.6308\n",
      "Epoch 190/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.6635 - val_mse: 0.6635\n",
      "Epoch 191/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6418 - mse: 0.6418 - val_loss: 0.6647 - val_mse: 0.6647\n",
      "Epoch 192/200\n",
      "129360/129360 [==============================] - 7s 51us/step - loss: 0.6405 - mse: 0.6405 - val_loss: 0.6632 - val_mse: 0.6632\n",
      "Epoch 193/200\n",
      "129360/129360 [==============================] - 7s 53us/step - loss: 0.6409 - mse: 0.6409 - val_loss: 0.6981 - val_mse: 0.6981\n",
      "Epoch 194/200\n",
      "129360/129360 [==============================] - 6s 47us/step - loss: 0.6429 - mse: 0.6429 - val_loss: 0.6914 - val_mse: 0.6914\n",
      "Epoch 195/200\n",
      "129360/129360 [==============================] - 6s 48us/step - loss: 0.6423 - mse: 0.6423 - val_loss: 0.6378 - val_mse: 0.6378\n",
      "Epoch 196/200\n",
      "129360/129360 [==============================] - 6s 49us/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.7093 - val_mse: 0.7093\n",
      "Epoch 197/200\n",
      "129360/129360 [==============================] - 6s 50us/step - loss: 0.6412 - mse: 0.6412 - val_loss: 0.6796 - val_mse: 0.6796\n",
      "Epoch 198/200\n",
      "129360/129360 [==============================] - 6s 50us/step - loss: 0.6421 - mse: 0.6421 - val_loss: 0.6803 - val_mse: 0.6803\n",
      "Epoch 199/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 0.7010 - val_mse: 0.7010\n",
      "Epoch 200/200\n",
      "129360/129360 [==============================] - 7s 54us/step - loss: 0.6438 - mse: 0.6438 - val_loss: 0.6614 - val_mse: 0.6614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f60a96796d8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with the Data\n",
    "model.fit(\n",
    "    train_X, \n",
    "    train_Y, \n",
    "    epochs = training_epochs, \n",
    "    validation_data = (valid_X, valid_Y), \n",
    "    verbose = 1,\n",
    "    callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15960/15960 [==============================] - 0s 24us/step\n",
      "Test Loss: 0.6691175418240684\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_X, test_Y)\n",
    "print(\"Test Loss:\", score[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f60a8b6c2b0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = model.get_weights() #Extract the weight of the model\n",
    "T = np.arange(0, 0.00625*stim, 0.00625) #Time interval of 1 sec containing stimuli points \n",
    "plt.plot(T, weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # tf Graph Input\n",
    "(size_L, size_C) = train_X.shape\n",
    "X = tf.placeholder(\"float\", [None,size_C])\n",
    "Y = tf.placeholder(\"float\",[None,1])\n",
    "\n",
    "W={}   #creation of a dictionary W, each key of the dictionary will contain the weights of a layer\n",
    "bb={}    #same for baby\n",
    "\n",
    "    # Set model weights\n",
    "hidden_layers_size = [size_C]+hidden_layers_size    #we add the number of columns of the base matrix (ex: 160) to the list of layers\n",
    "print(hidden_layers_size)                           # ex : 160 2 3 1\n",
    "\n",
    "for i,j in enumerate(hidden_layers_size[:-1]):\n",
    "        W_tmp = tf.Variable(tf.fill([j,hidden_layers_size[i+1]],rng.randn()))  # For each index i having the value j excluding the last layer (ex: 0: 160, 1: 2, 2: 3)\n",
    "        W[i+1] = W_tmp   #we create a tensorflow variable W having for size (layer * next_layer) #ex: 3 layers W: 160 * 2, 2 * 3, 3 * 1\n",
    "    \n",
    "        bb_tmp = tf.Variable(tf.fill([hidden_layers_size[i+1]],rng.randn()))   #we create a tensorflow variable W having for size (next_layer)\n",
    "        bb[i+1] = bb_tmp    #we add a new key to the dictionary, containing the new layer (key index: 1 2 3 ... to change according to preference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X.shape)\n",
    "print (W)\n",
    "print (bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Construct a linear model\n",
    "#hiddenX = tf.nn.xw_plus_b(X,W1,bb1)\n",
    "#pred = tf.nn.xw_plus_b(hiddenX,W2,bb2)\n",
    "\n",
    "hidden_X_tmp = X  #corresponds to the data that we enter (extract_X)\n",
    "hidden_X = {}      #similar to W: creation of a dictionary storing the hidden_X of the different layers\n",
    "i = 1\n",
    "\n",
    "while i <= len(W):\n",
    "    hidden_X_tmp = tf.nn.xw_plus_b(hidden_X_tmp,W[i],bb[i])   #2 times the same values ​​for two neurons of the same layer ... the problem may come from here\n",
    "    hidden_X[i] = hidden_X_tmp\n",
    "    i=i+1\n",
    "\n",
    "print (hidden_X)\n",
    "pred = hidden_X[len(W)]     #pred corresponds to the hidden_X of the last layer - review the indexing?\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Mean squared error\n",
    "cost_train = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples_train)\n",
    "cost_valid = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples_valid)\n",
    "cost_test = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples_test)\n",
    "    # Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "   # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(optimizer, feed_dict={X: train_X, Y: train_Y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            cost = sess.run(cost_train, feed_dict={X: train_X, Y:train_Y})\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(cost))\n",
    "            costV = sess.run(cost_valid, feed_dict={X: valid_X, Y: valid_Y})\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"valid_cost=\", \"{:.9f}\".format(costV))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost_train, feed_dict={X: train_X, Y: train_Y})\n",
    "    print (\"training_cost = \", training_cost) \n",
    "    test_cost = sess.run(cost_test, feed_dict={X: test_X, Y: test_Y})\n",
    "    print (\"test_cost = \", test_cost)\n",
    "    \n",
    "       #Graphic display\n",
    "        \n",
    "    T = np.arange(0, 0.00625*stim, 0.00625)                       # creation of the time variable (on 1s) for the abscissa\n",
    "    \n",
    "    nbr_elct = len(electi)\n",
    "    (Lo_W, la_W) = W[1].shape\n",
    "    Lo_W = int(Lo_W)                                              # number of lines: inputs (160 * nbr_electrodes, for example)\n",
    "    la_W = int(la_W)                                              # number of columns: number of neurons in the layer\n",
    "    \n",
    "    z=0\n",
    "    while z < nbr_elct:                                           # for each electrode\n",
    "        z_1=0 \n",
    "        while z_1 < la_W:                                         # for each neuron of the W layer [1]\n",
    "            W_tmp = tf.slice(W[1], [0, z_1], [Lo_W, 1])           # slice: starting value [line 0, column of the neuron], dimensions of the section [160 * nbr_electrodes lines, 1 column])\n",
    "            W_tmp = tf.slice(W_tmp, [z*stim, 0], [stim, 1])       # slice: starting value [first value of the new electrode, column 0], dimensions of the section [160 lines, 1 column]\n",
    "            print (W_tmp.shape)\n",
    "            \n",
    "            plt.plot(T, sess.run(W_tmp), label= (\"neurone_\", z_1, \"layer_1, electrode_\", electi[z]))\n",
    "            z_1 = z_1+1\n",
    "            \n",
    "        z = z+1\n",
    "        \n",
    "    plt.legend()    \n",
    "    plt.show()\n",
    "    #plt.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
